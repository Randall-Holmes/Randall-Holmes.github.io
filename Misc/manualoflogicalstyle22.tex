\documentclass[12pt]{article}

\usepackage{amssymb}

\usepackage{comment}

\title{Manual of Logical Style (fresh version 2022)}

\author{Randall Holmes}

\date{8/19/2022}

\begin{document}

\maketitle
\tableofcontents


\section{Introduction}

This is a fresh version of a document I have been working on with my classes at various levels for years.  The idea that I am promoting is that the logical form of a statement we are trying to prove, or the logical form of statements we have proved or are assuming for the sake of argument, can be used to guide the writing of proofs, sometimes almost automatically$\ldots$to a certain point where we have to think.

The document is organized by logical operation (the top level logical operation of the statement we are looking at) and under each logical operation as a heading we have to consider separately on the one hand how to prove a statement of that form, and on the other hand how to use a statement of that form which we have proved or assumed in the proof of another statement.

This document introduces fancy logical notation but the intention is that the reader should learn how to handle the same logical structures of statements when they occur in English, as they do in mathematical writing all the time.

{\bf Boneheaded errors in this document (or any posted handout) are likely, and I will award points to students who point them out to me.  The first one to find an error gets the points (unless it is me, of course).}

\section{Arguments, valid or otherwise}

An {\em argument} is a list of statements in the following format:

$$\begin{array}  {c}

P_1 \\

\vdots \\

P_n \\ \hline

C \end{array}$$

where the $P_i$'s are the {\em premises\/} and $C$ is the {\em conclusion\/}.  An argument is {\em valid\/} if every assignment of values to variables appearing in the argument which makes all the premises true also makes the conclusion true.

We will use argument format mostly to express formal rules of reasoning compactly.  The Marcel theorem prover which we will introduce later manipulates arguments, as you will see.

A single line representation of an argument as $P_1,\ldots,P_n \vdash C$ may also be useful.

\newpage

\subsection{Using truth tables to determine whether (small) arguments are valid or invalid}

We give an example of a valid argument.  Some simple valid arguments (including this one) we will call {\em logical rules\/} because they are building blocks of general arguments for us.

The argument

$$\begin{array}{c}

A \\

A \rightarrow B \\ \hline 

B \\

\end{array}$$

is valid, and it should be intuitively convincing that it is:  if we have that $A$ is true, and that it is true that if $A$, then $B$, then we surely expect $B$ to be true.  We call it a logical rule and give it the traditional Latin nickname {\em modus ponens\/}.

We present a truth table verification of this.

$$\begin{array}{c||c|c||c|c||c}

& A & B & A ({\bf P_1}) & A \rightarrow B ({\bf P_2)} & B ({\bf C}) \\
 1 & T & T & T & T& T \\

2 & T & F & T & F & T \\

3 & F & T & F & T & T \\

4 & F & F & F & T & T \\

\end{array}$$

The only line in which both premises are true is line 1, and on this line the conclusion is true.  So the argument presented is valid.

We present another valid argument, which is not a logical rule for us but is in other commonly used presentations of propositional logic, and as such has a name, {\em transitivity of implication\/}.

The argument is

$$\begin{array}{c}

A \rightarrow B \\

B \rightarrow C \\ \hline

A \rightarrow C

\end{array}$$

\newpage

Again, it should be quite intuitively convincing that this is valid.

$$\begin{array}{c||c|c|c||c | c||c}

& A & B & C & A \rightarrow B ({\bf P_1})& B \rightarrow C ({\bf P_2})& A \rightarrow C ({\bf C})\\

1 & T & T & T & T & T & T \\

2 & T & T & F & T & F & F \\

3 & T & F & T & F & T & T \\

4 & T & F & F & F & T & F \\

5 & F & T & T & T & T & T \\

6 & F & T & F & T & F & T \\

7 & F & F & T & T & T & T \\

8 & F & F & F &  T & T & T \\

\end{array}$$

The premises are all true on lines 1,5,7,8, and in each of these lines the conclusion is also true, so the argument is valid.

We give an example of a common argument which is not valid.  Such arguments may be called {\em fallacies\/} if they represent common errors in reasoning:  I think this one is often called arguing to the converse.

The argument is

$$\begin{array}{c}

A \rightarrow B \\ \hline

B \rightarrow A \\ 

\end{array}$$

Here is the relevant truth table

$$\begin{array}{c||c|c||c|c||c}

& A & B & A \rightarrow B ({\bf P_1})& B \rightarrow A ({\bf C})\\

1 & T & T & T & T \\

2 & T & F & F & T \\

3 & F & T & T & F \\

4 & F & F & T & T \\

\end{array}$$

There is only one premise, and it is true (so all the premises are true) in lines 1,3,4.  The argument is not valid, because in line 3, which has all premises true, the conclusion is false.

Notice that verifying validity requires you to look at many rows of the table, as a rule:  you need to verify that every row of the table which has T for each premise has T for the conclusion.  To verify invalidity, it is always sufficient to find a single row in which all the premises are T and the conclusion is F.

\section{Variables}

In the first sections, we will use capital letters as {\em propositional variables\/}:  these are variable {\em sentences\/} as it were.  



\newpage

\section{Conjunction}

This section is about ``and".  We use the notation $P \wedge Q$ to represent ``$P$ and $Q$".

The truth table for this operation is

$$\begin{array}{cc|c}

P & Q & P \wedge Q \\ \hline \hline

T & T & T \\ \hline
T & F & F \\ \hline
F & T & F \\ \hline
F & F & F \\ \hline

\end{array}$$

This document is not about truth table reasoning, but truth tables are useful for making it clear what we mean.

The plan for proving a statement $A \wedge B$ is simplicity itself:  first prove $A$, then prove $B$.  We just prove one after the other, with no special local assumptions.

This is summarized in a logical rule (when we say that an argument is a logical rule, we are just saying that it is valid (and important as a basic form of valid argument)).

$$\begin{array}{c}

A \\

B \\ \hline

A \wedge B

\end{array}$$

This is called the rule of {\em conjunction\/}.

The plan for using a conjunction $A \wedge B$ which we have proved or assumed is also simplicity itself.  We can draw the conclusion $A$.  We can draw the conclusion $B$.
In other words, we can just pull it apart.

This is summarized in two rules:

$$\begin{array}{c}

A \wedge B \\ \hline

A


\end{array}$$

and

$$\begin{array}{c}

A \wedge B \\ \hline

B


\end{array}$$

Both of these rules are called rules of {\em simplification}.

\newpage

\section{Implication}

This section is about ``if$\ldots$, then$\ldots$" statements, which are also called {\em conditional statements\/}.  We use the notation $A \rightarrow B$ to represent
``If $A$ then $B$".

The truth table for this operation is

$$\begin{array}{cc|c}

P & Q & P \rightarrow Q \\ \hline \hline

T & T & T \\ \hline
T & F & F \\ \hline
F & T & T \\ \hline
F & F & T \\ \hline

\end{array}$$

The plan for proving an implication (conditional statement) $A \rightarrow B$ takes a little thought to understand.  The strategy is to assume $A$ for the sake of argument,
then deduce $B$.  When you finish this argument, you have {\em not\/} proved $B$ (nor have you proved any of the intervening steps), because they all depend on the assumption $A$ that you made for the sake of argument.  But you have proved $A \rightarrow B$.  Here is a format for this kind of argument:

\begin{description}

\item[Prove:]  $A \rightarrow B$

\begin{description}

\item[Assume (1):]  $A$  (we give any statement we can use a line number so we can refer to it, when we are being very formal).

\item[Goal:]  $B$ (the goal is just a comment:  notice that we do not give it a line number, since we cannot {\em use\/} it).

\item[intervening proof steps:]  $\vdots$

\item[($n$):]  $B$

\end{description}

\item[($n+1$):]  $A \rightarrow B$ rule of deduction, lines $1$-$n$

\end{description}

The lines using the assumption $A$ are indented, and we need to remember that once we have proved $A \rightarrow B$ we are no longer entitled to refer to anything in that block of statements, because all those lines depend (presumably) on the assumption $A$ which we are no longer making.
\newpage
A suggestion of how to make this more formal follows in tiny print.
\newline {\tiny
A suggestion of how to formalize this rule completely is given by

$$\begin{array}{c}

A \vdash B \\ \hline

A \rightarrow B

\end{array}$$

or even 


$$\begin{array}{c}

[P_1,\ldots,P_n, ]A \vdash B \\ \hline

[P_1,\ldots,P_n, \vdash ]A \rightarrow B

\end{array}$$

In the second version, the additional $P_i$'s can be thought of as the hypotheses of larger indented boxes containing the one we introduced for the hypothesis $A$.  The general idea is, if we can deduce $B$ from $A$ [and possibly some other hypotheses] then we can conclude $A \rightarrow B$ [without the hypothesis $A$ but with the others if there are any].}

Using an implication is different (and simpler).  This can be expressed in a formal rule:


$$\begin{array}{c}

A \\

A \rightarrow B \\ \hline

B

\end{array}$$




If we know (or have assumed) $A$ and we know (or have assumed) $A \rightarrow B$, then we can draw the conclusion $B$.  This rule is called {\em modus ponens\/}.

There are some other rules for indirect reasoning with conditional statements, which we will introduce below after we discuss negation.

\newpage

\section{Biconditional (If and only if)}

This section is about ``if and only if", or {\em biconditional\/} statements.  We use the notation $A \leftrightarrow B$ to represent $A$ if and only if $B$, for which we also use the abbreviation ``$A$ iff $B$".

The truth table for this operation is:

$$\begin{array}{cc|c}

P & Q & P \leftrightarrow Q \\ \hline \hline

T & T & T \\ \hline
T & F & F \\ \hline
F & T & F \\ \hline
F & F & T \\ \hline

\end{array}$$

We can also {\em define\/} $A \leftrightarrow B$ as $(A \rightarrow B) \wedge (B \rightarrow A)$.

The strategy for proving a statement $A \leftrightarrow B$ takes the form which the definition above suggests:  first prove that $A$ implies $B$, then prove that $B$ implies $A$.

\begin{description}

\item[Prove:]  $A \leftrightarrow B$

\item[Part I:]

\begin{description}

\item
\item[Assume (1):]  $A$

\item[Goal:]  $B$

\item[intervening proof steps:]  $\vdots$

\item[($n$):]  $B$

\end{description}

\item[($n+1$):]  $A \rightarrow B$ by deduction lines $1-n$  [optional]



\item[Part II:]

\begin{description}

\item
\item[Assume ($(n+2)$):]  $B$

\item[Goal:]  $A$

\item[intervening proof steps:]  $\vdots$

\item[($m$):]  $A$

\end{description}

\item[($m+1$):]  $B \rightarrow A$ by deduction lines $(n+2)-m$ [optiona1]

\item[($m+2$):]  $A \leftrightarrow B$ by biconditional introduction, lines $n+1$, $m+1$ [if these implication lines are supplied] or by $1$-$n$, $(n+2)$-$m$; you may either explicitly prove the two implications and use them as references for the proof of the biconditional, or leave them out and use the two blocks of statements as the reference for the proof of the biconditional.  Either style is allowed.

\end{description}

A biconditional $A \leftrightarrow B$ can be used in a proof in a way similar to the way a conditional is used, but in either direction:

$$\begin{array}{c}

A \\

A \leftrightarrow B \\ \hline

B

\end{array}$$

$$\begin{array}{c}

B \\

A \leftrightarrow B \\ \hline

A

\end{array}$$

are both valid rules, which we might call {\em biconditional modus ponens\/}.

{\tiny There is a more general way of using a statement $A \leftrightarrow B$ which we will {\em not\/} as a rule use in our formal logic exercises, but which you should be aware of.
If we have proved $A \leftrightarrow B$, we have shown that $A$ and $B$ are effectively saying the same thing, so we may freely substitute $A$ for $B$ and $B$ for $A$.
For example, because the de Morgan law $\neg(A \wedge B) \leftrightarrow (\neg A \vee \neg B)$ is a theorem, it is valid to replace $\neg(A \wedge B)$ with $\neg A \vee \neg B$ or vice versa
in a more complicated logical expression as a step in a proof.  We note that this is valid, but we do {\em not\/} allow use of this in exercises unless we specifically say so (for example, we might want to prove the de Morgan laws using our regular rules;  certainly you are not allowed to use this substitution strategy to short-circuit the exercise).}

\newpage

\section{A short sample proof}

\begin{description}

\item[Prove:]  $((A \rightarrow B) \wedge (B \rightarrow C)) \rightarrow (A \rightarrow C)$

We start by applying the proof strategy for implication.

\begin{description}

\item[Assume (1):]  $(A \rightarrow B) \wedge (B \rightarrow C)$

\item[Goal:]  $A \rightarrow C$

We again apply the proof strategy for implication.

\begin{description}

\item[Assume (2):]  $A$

\item[Goal:]  $C$

We can't do anything more with this goal, as it is as simple as possible.  We use simplification to unpack assumption 1.

\item[(3):]  $A \rightarrow B$  simplification, line 1

\item[(4):]  $B \rightarrow C$ simplification, line 1

\item[(5):]  $B$ modus ponens, lines 2,3

\item[(6):]  $C$ modus ponens, lines 4,5

\end{description}

\item[(7):]  $A \rightarrow C$  deduction lines 2-6

\end{description}

\item[(8):]  $((A \rightarrow B) \wedge (B \rightarrow C)) \rightarrow (A \rightarrow C)$ deduction lines 1-7

\end{description}

\newpage

\section{A longer sample proof}

This was done in class.

\begin{description}

\item[Theorem:]  $(A \rightarrow (B\rightarrow C)) \leftrightarrow ((A \wedge B) \rightarrow C)$

This is a biconditional statement, which determines our initial setup.

\item[Part I:]

\begin{description}

\item

\item[Assume(1):]  $A \rightarrow (B \rightarrow C)$

\item[Goal:]  $(A \wedge B) \rightarrow C$

This goal is an implication, which again determines our setup.

\begin{description}

\item[Assume(2):]  $A \wedge B$

\item[Goal:]  $C$

The goal $C$ is as simple as possible, so it is time for us to look into {\em using\/} the numbered lines we have.

Notice that we could apply modus ponens with line 1 if we had the hypothesis $A$ of line 1 as a line, and we can get
$A$ as a line by unpacking line 2.

\item[(3):]  $A$ simp line 2

\item[(4):]  $B \rightarrow C$ m.p. lines 1,3

Now we can apply modus ponens if we can get $B$ as a line, and once again we can get $B$ as a line from line 2.

\item[(5):]  $B$ simp line 2

\item[(6):]  $C$  modus ponens lines 4,5

This is our goal above, so it is time for closing lines.

\end{description}

\item[(7):]  $(A \wedge B) \rightarrow C$  deduction lines 2-6.

\end{description}

This completes Part I.  We continue with Part II on the next page.

\newpage

\item[Part II:]

\begin{description}

\item[Assume(8):]  $(A \wedge B) \rightarrow C$

\item[Goal:]  $A \rightarrow (B \rightarrow C)$

\begin{description}

\item[Assume(9):]  $A$

\item[Goal:] $B \rightarrow C$

\begin{description}

\item[Assume(10):]  $B$

\item[Goal:] $C$

This is the limit of the goal unpacking process: now we need to start using our numbered lines.  Notice that we
would like to have $A \wedge B$ as a line in order to apply m.p. with line 8.  And we can get $A \wedge B$ from lines 9 and 10.

\item[(11):]  $A \wedge B$  conjunction lines 9,10

\item[(12):]  $C$ m.p. lines 8,11

\end{description}

\item[(13):]  $B \rightarrow C$  deduction lines 10-12

\end{description}

\item[(14):]  $A \rightarrow (B \rightarrow C)$ deduction lines 8-13

\end{description}

\item[(15):]  the Theorem, by biconditional introduction, lines 1-7, 8-14.




\end{description}

\newpage

\section{Disjunction}

This section is about ``or" (more precisely about ``and/or").  We use the notation $P \vee Q$ to represent ``$P$ or $Q$ (or both)".

The truth table for this operation is

$$\begin{array}{cc|c}

P & Q & P \vee Q \\ \hline \hline

T & T & T \\ \hline
T & F & T \\ \hline
F & T & T \\ \hline
F & F & F \\ \hline

\end{array}$$

The basic rules for proving disjunctions may seem very limited.  A more powerful rule for proving disjunctions will be developed in a later section.

These rules are embodied in the two rules of {\em addition\/}:

$$\begin{array}{c}

A  \\ \hline

A \vee B

\end{array}$$

and

$$\begin{array}{c}

B  \\ \hline

A \vee B

\end{array}$$

To prove $A \vee B$, either prove $A$ or prove $B$.  This might not seem like enough, but we will see that it is.

The rule for using an ``or" statement which is been proved or assumed is {\em proof by cases\/}.  This can be packaged as a rule:

$$\begin{array}{c}

P \vee Q \\

P \rightarrow C \\

Q \rightarrow C \\ \hline

C


\end{array}$$

or as a strategy with indented blocks of the kind we have been presenting:

\begin{description}

\item[(1):]  $P \vee Q$

\item[possible intervening proof lines:] $\vdots$

\item[Goal:] $C$

\item[Case 1:]

\begin{description}

\item

\item[Assume (1a):]  $P$

\item[Goal:]  $C$

\item[intervening proof steps:] $\vdots$

\item[(n):]  $C$

\end{description}

\item[Case 2:]

\begin{description}
\item

\item[Assume (1b):]  $Q$

\item[Goal:]  $C$

\item[intervening proof steps:] $\vdots$

\item[(m):]  $C$

\end{description}

\item[(m+1):]  $C$ proof by cases by 1, 1a-n, 1b-m

\end{description}

Proofs by cases are ubiquitous in mathematical reasoning.  Notice that in the block format, each of the cases could be recast as a proof of
an implication by deduction, then the rule of proof cases in the argument form given above could be used to justify the conclusion.

We give an example of a proof by cases done in class.

\begin{description}

\item[Theorem:]  $((A \rightarrow C) \wedge (B \rightarrow C)) \rightarrow ((A\vee B)\rightarrow C)$

This statement looks almost like a statement of the rule of proof by cases, so it is not surprising that we use the rule to prove it.

\begin{description}

\item[Assume(1):]  $(A \rightarrow C) \wedge (B \rightarrow C)$

\item[Goal:]  $(A\vee B) \rightarrow C$

\begin{description}

\item[Assume(2):]  $A \vee B$

Once we have a numbered line which is an or statement, we should expect a proof by cases as at least a possibility.

\item[Goal:]  $C$

and indeed we start a proof by cases, which starts on the next page.

\newpage

\item[Case I (from line 2):]

\begin{description}

\item[Assume (2a):]  $A$

\item[Goal:]  $C$

Now we need to look at our numbered lines.  If we unpack line 1, we get something useful.

\item[(3a):]  $A \rightarrow C$ simp line 1

\item[(4a):]  $C$ m.p. lines 2a,3a

which is our goal.

\end{description}

\item[Case II (from line 2):]

\begin{description}

\item[Assume (2b):]  $B$

\item[Goal:]  $C$

Now we need to look at our numbered lines.  If we unpack line 1, we get something useful.

\item[(3b):]  $B \rightarrow C$ simp line 1

\item[(4b):]  $C$ m.p. lines 2a,3a

which is our goal.

\end{description}

\item [(5):]  $C$ proof by cases, 2, 2a-4a, 2b-4b

Proofs by cases have our most complicated line references, the line for the ``or" assumption
and a block for the proof of each case.

\end{description}

\item[(6):]  $(A \vee B) \rightarrow C$  deduction 2-5

\end{description}

\item[(7):]  the Theorem, deduction lines 1-6.

\end{description}

Here is a short proof to illustrate the use of the rule of addition.

\begin{description}

\item[Prove:]  $(A \rightarrow B) \rightarrow (A \rightarrow( B \vee C)))$

\begin{description}

\item[Assume(1):]  $A \rightarrow B$

\item[Goal:]  $A \rightarrow (B \vee C)$

\begin{description}

\item[Assume(2):]  $A$

\item[Goal:]  $B \vee C$

\item[(3):]  $B$  m.p. 1,2

\item[(4):]  $B \vee C$ addition line 3

\end{description}

\item[(5):]  $A \rightarrow (B \vee C)$  deduction lines 2-4

\end{description}

\item[(6):]  $(A \rightarrow B) \rightarrow (A \rightarrow( B \vee C)))$ (the theorem) by deduction lines 1-5.

\end{description}

\newpage

\section{Exercises}

Write formal proofs in the style given above of each theorem.

\begin{enumerate}

\item $(A \wedge B) \rightarrow (B \wedge A)$

\item $(A \wedge (A \rightarrow B)) \rightarrow B$

\item $(A \rightarrow (B \wedge C)) \rightarrow (A \rightarrow C)$

\item $((A \rightarrow B) \wedge (B \rightarrow C) \wedge (C \rightarrow D)) \rightarrow (A \rightarrow D)$.

Note in this problem that I will allow you to reason from $X \wedge Y \wedge Z$ to $X$, or to $Y$, or to $Z$, by a single application of simplification.  This makes life simpler.

\item $(A \vee B) \rightarrow (B \vee A)$  Hint: you will want to prove this by cases on the hypothesis $A \vee B$.  Notice that we do have rules which allow deduction
of $B \vee A$ from $A$ and from $B$ (the rule of addition).

\item Use the truth table method to verify that the rule of {\em modus tollens\/}

$$\begin{array}{c}

A \rightarrow B \\ 

\neg B \\ \hline

\neg A \\

\end{array}$$

is a valid argument.  Be sure to include a discussion in English of the properties of rows and/or columns of the truth table which show this.

\item Use the truth table method to show that this argument (I think it is called {\em denying the antecedent\/}) is invalid.

$$\begin{array}{c}

A \rightarrow B \\ 

\neg A \\ \hline

\neg B \\

\end{array}$$

Be sure to include a discussion in English of the properties of rows and/or columns of the truth table which show this.

\end{enumerate}

\newpage

\section{Negation}

This section is about ``not".  We introduce the notation $\neg P$ for ``It is not the case that $P$", or equivalently ``$P$ is false".   To make it easier to state the rules for negation,
we also introduce the symbol $\perp$ for a fixed false statement.  We will refer to $\perp$ as ``the absurd" on occasion.

The truth table for this operation is

$$\begin{array}{c|c}

P &  \neg P \\ \hline \hline

T & F \\ \hline

F & T \\ \hline

\end{array}$$

To prove a statement $\neg P$, assume $P$ and reason to $\perp$.

\begin{description}

\item[Prove:]  $\neg P$

\begin{description}

\item[Assume (1):]  $P$

\item[Goal:]  $\perp$ (we can express this by saying that our goal is a contradiction)

\item[intervening proof steps:]  $\vdots$

\item[($n$):]  $\perp$

\end{description}

\item[($n+1$):]  $\neg P$ by negation introduction, lines $1$-$n$

\end{description}

There are two rules for using negative statements:

$$\begin{array}{c}

P \\

\neg P \\ \hline

\perp

\end{array}$$

This is the {\em rule of contradiction\/}, the only way to prove the absurd.  We hope this never happens except under (unfortunate) assumptions made for the sake of argument!

$$\begin{array}{c}

\neg \neg P \\ \hline

P

\end{array}$$

This is the rule of {\em double negation elimination\/}.

One might think that the strategy we call ``negation introduction" is the famous strategy usually called ``proof by contradiction" or ``reductio ad absurdum" (we prefer the Latin name since we have another rule called ``contradiction").  It isn't quite:  it is the direct strategy for proving a negative statement.  Reductio ad absurdum is more general (it can be applied to prove statements of any form).

This proof strategy for a statement of any form $P$

\begin{description}

\item[Prove:]  $P$

\begin{description}

\item[Assume (1):]  $\neg P$

\item[Goal:]  $\perp$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $\perp$



\end{description}

\item[(n+1):]  $\neg \neg P$ negation introduction, lines 1-n

\item[(n+2):]   $P$ d.n.e, line $n+1$.


\end{description}

can be packaged more compactly as 


\begin{description}

\item[Prove:]  $P$

\begin{description}

\item[Assume (1):]  $\neg P$

\item[Goal:]  $\perp$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $\perp$



\end{description}

\item[(n+1):]  $P$, reductio ad absurdum, lines 1-n.


\end{description}

The rule of ``proof by contradiction" or ``reductio ad absurdum" is thus seen to be a derived rule of our system, justified by negation introduction and double negation elimination.  It is a very useful rule:  a point of proof strategy is to attempt proof by contradiction whenever you cannot see what else to do.

We give some other useful derived rules.

We state and justify the rule of {\em double negation introduction\/}.

$$\begin{array}{c}

P \\ \hline

\neg \neg P

\end{array}$$

states the rule.  The justification follows.

\begin{description}

\item[premise(1):]  $P$

\item[Goal:]  $\neg\neg P$

\begin{description}

\item[Assume (2):]  $\neg P$

\item[Goal:]  $\perp$

\item[(3):]  $\perp$ contradiction 1,2


\end{description}

\item[(4):]  $\neg \neg P$ negation introduction, 2-3.

\end{description}

You are allowed to freely use the derived rule of double negation introduction.

It is a feature of the truth table definition of implication that anything follows from a false statement.  We prove this in our format.

\begin{description}

\item[premise(1):]  $\perp$

\item[Goal:]  $P$

\begin{description}

\item[Assume(2):]  $\neg P$

\item[Goal:]  $\perp$

\item[(3):]  $\perp$  copied from 1

\end{description}

\item[(4):]  $P$ reductio ad absurdum 2-3.


\end{description}

We have verified that

$$\begin{array}{c}

\perp \\ \hline

P

\end{array}$$

is a valid argument.  Any conditions which made all premises of this argument true (there are no such conditions) also make its conclusion true!  We allow this to be used
as a rule and call it ``absurdity".


\newpage

\section{Implication and negation}

In this section, we prove the Contrapositive Theorem then use it to justify the strategy of indirect proof for proving implications and the rule of modus tollens for using implications.  In general terms, we present useful rules and strategies which combine the operations of implication and negation.

\begin{description}

\item[Theorem:]  $(P \rightarrow Q) \leftrightarrow (\neg Q \rightarrow \neg P)$

\item[Part I:]

\begin{description}
\item

\item[Assume(1):]  $P \rightarrow Q$

\item[Goal:]  $\neg Q \rightarrow \neg P$

\begin{description}

\item[Assume(2):]  $\neg Q$

\item[Goal:]  $\neg P$

\begin{description}

\item[Assume(3):]  $P$

\item[Goal:]  $\perp$

\item[(4):]  $Q$  m.p. 1,3

\item[(5):]  $\perp$  contradiction 2,4

\end{description}

\item[(6):]  $\neg P$ negation introduction, lines 3-5
\end{description}
\item[(7):]  $\neg Q \rightarrow \neg P$  deduction lines 2-6
\end{description}

\item[Part II:]

\begin{description}
\item

\item[Assume(8):]  $\neg Q \rightarrow \neg P$

\item[Goal:]  $P \rightarrow Q$

\begin{description}

\item[Assume(9):]  $P$

\item[Goal:]  $Q$

We prove this goal by reductio ad absurdum (we cannot see any other line of attack!)

\begin{description}

\item[Assume(10):]  $\neg Q$

\item[Goal:]  $\perp$

\item[(11):]  $\neg P$  deduction 8,10

\item[(12);]  $\perp$ contradiction 9,11

\end{description}

\item[(13):]  $Q$  reductio ad absurdum 10-12

\end{description}

\item[(14):]  $P \rightarrow Q$  deduction 9-13

\end{description}

\item[(15):]  The Theorem, by biconditional introduction, 1-7, 8-14

\end{description}

The Contrapositive Theorem justifies some new strategies and rules.  The first is indirect proof of an implication.

\begin{description}

\item[Prove:]  $P \rightarrow Q$

\begin{description}

\item[Assume(1):] $\neg Q$

\item[Goal:]  $\neg P$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $\neg P$


\end{description}

\item[(n+1):]  $P \rightarrow Q$ indirect proof, 1-n

\end{description}

This can be seen to be justified in terms of rules and theorems above by adding some extra steps:

\begin{description}

\item[Prove:]  $P \rightarrow Q$

\item[Prove:]  $\neg Q \rightarrow \neg P$

\begin{description}

\item[Assume(1):] $\neg Q$

\item[Goal:]  $\neg P$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $\neg P$


\end{description}

\item[(n+1):]  $\neg Q \rightarrow \neg P$ deduction 1-n

\item[(n+2):]  $(P \rightarrow Q) \leftrightarrow (\neg Q \rightarrow \neg P)$  contrapositive theorem

\item[(n+3):]  $P \rightarrow Q$ biconditional m.p., n+1-n+2
\end{description}

Similarly, we could use the contrapositive theorem to justify a new rule for using implications:

$$\begin{array}{c}

P \rightarrow Q \\

\neg Q \\ \hline

\neg P

\end{array}$$

We give a formal justification of this rule using our rules and theorems from above.  This rule is called {\em modus tollens\/}.

\begin{description}

\item[premise(1):]  $P \rightarrow Q$

\item[premise(2):]  $\neg Q$

\item[Goal:]  $\neg P$

\begin{description}

\item[Assume(3):]  $P$

\item[Goal:]  $\perp$

\item[(4):]  $Q$  m.p. 1,3

\item[(5):]  $\perp$ contradiction 2,4

\end{description}

\item[(6):]  $\neg P$  negation introduction 3-5

\end{description}

which establishes the validity of the rule, without actually using the contrapositive theorem, though it should be easy to see that the contrapositive theorem could be used for this.


\newpage

\section{Disjunction and negation}

In this section, we prove the validity of a definition of disjunction in terms of negation and implication and use it to motivate a more powerful rule
of {\em alternative elimination\/} for proving disjunctions, and we introduce the rule of {\em disjunctive syllogism\/} for using disjunctions.  In general terms, we present useful rules and strategies which combine the operations of disjunction and negation.

We note (you can verify this using truth tables) that $P \vee Q$ is logically equivalent to $\neg P \rightarrow Q$ and also to $\neg Q \rightarrow P$.

This suggests the following strategy (really a pair of strategies) for proving $P \vee Q$.

\begin{description}

\item[Prove:]  $P \vee Q$

\begin{description}


\item[Assume(1):]  $\neg P$

\item[Goal:]  $Q$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $Q$

\end{description}

\item[(n+1):]  $P \vee Q$ alternative elimination 1-n

\end{description}

The form below is just as good.  You should not give proofs of both forms for the same statement (this would be redundant).

\begin{description}

\item[Prove:]  $P \vee Q$

\begin{description}

\item[Assume(1):]  $\neg Q$

\item[Goal:]  $P$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $P$

\end{description}

\item[(n+1):]  $P \vee Q$ alternative elimination 1-n

\end{description}

We present a justification for the first style of alternative elimination (a justification for the second would be very similar).

\begin{description}

\item[Prove:]  $P \vee Q$

\item[[[Prove:]  $\neg P \rightarrow Q$]]

\begin{description}


\item[Assume(1):]  $\neg P$

\item[Goal:]  $Q$

\item[intervening proof steps:]  $\vdots$

\item[(n):]  $Q$

\end{description}

\item[[[(n+1):]  $\neg P \rightarrow Q$ deduction 1-n

\begin{description}

\item[Assume(n+2):] $\neg(P \vee Q)$ for the sake of a contradiction.

\item[Goal:]  $P$ in order to show $P \vee Q$ by addition and get a contradiction

\begin{description}

\item[[Assume(n+3):]  $\neg P$

\item[(n+4):]  $Q$ mp n+1,n+3

\item[(n+5):]  $P \vee Q$ addition n+4

\item[(n+6):]  $\perp$ contradiction n+5, n+2

\end{description}

\item[(n+7):]  $P$ reductio ad absurdum n+3-n+6

\item[(n+8):]  $P \vee Q$ addition n+7

\item[(n+9):]  $\perp$ contradiction n+2,n+7]]

\end{description}

\item[(n+10):]  $P \vee Q$ reductio ad absurdum, n+1-n+9

\end{description}

The double brackets indicate parts of this proof to be dropped to give the form of the alternative elimination rule, which is revealed by this proof to be a valid strategy to prove disjunctions.  Of course one would change the justification of the last line to ``alternative elimination" if one dropped the bracketed material.  We give this for completeness:  really, for this class I just want you to know the alternative elimination rule.

A useful rule for using disjunctions takes the following four forms, which are all called {\em disjunctive syllogism\/}.

$$\begin{array}{c}

P \vee Q \\ 

\neg P \\ \hline

Q
\end{array}$$


$$\begin{array}{c}

P \vee Q \\ 

\neg Q \\ \hline

P
\end{array}$$$$\begin{array}{c}

\neg P \vee Q \\ 

P \\ \hline

Q
\end{array}$$$$\begin{array}{c}

P \vee \neg Q \\ 

Q \\ \hline

P
\end{array}$$

Each of these can be motivated by using truth table equivalences:  for example the first follows from modus ponens combined with the equivalence of $P \vee Q$ to
$\neg P \rightarrow Q$.

We give a proof of the first form using our other rules.  We use the same device of double brackets to indicate parts to be deleted to give the disjunctive syllogism form.

\begin{description}

\item[(1):]  $P \vee Q$  premise

\item[(2):]  $\neg P$ premise

\item[Goal:]  $Q$

We will prove the goal by cases on (1).

\item[Case 1:]  

\begin{description}

\item

\item[Assume(1a):]  $P$

\item[Goal:] $Q$

\item[(2a):]  $\perp$   contradiction 1a,2

\item[(3a):]  $Q$ absurdity, 2 (we showed above that we can deduce anything from $\perp$).

\end{description}

\item[Case 2:]

\begin{description}

\item

\item[Assume(1b):]  $Q$

\item[Goal:]  $Q$

\end{description}

\item[(3):] $Q$ proof by cases 1, 1a-3a, 1b-1b


\end{description}

You do not need to know how to prove the rule of disjunctive syllogism, just how to use it.  But we give the justification for the sake of completeness.  More examples of the use of the various rules are found in the next section.

\section{More examples}

An example of a positive proof (using rules that do not involve negation).

\begin{description}

\item[Theorem:]  $((A \wedge B) \vee (B \wedge C)) \rightarrow B$

\begin{description}

\item[Assume(1):]  $(A \wedge B) \vee (B \wedge C)$

\item[Goal:]  $B$

We prove this by cases on (1).  This is basically the only thing we can do, if we are confined to the positive rules!

\item[Case 1:]

\begin{description}

\item

\item[Assume(1a):]  $A \wedge B$

\item[Goal:]  $B$

\item[(2a):]  $B$ simp line 1a


\end{description}


\item[Case 2:]  

\begin{description}

\item[Assume(1b):]  $B \wedge C$

\item[Goal:]  $B$

\item[(2b):]  $B$  simp line 1b
\end{description}

\item[(3):]  $B$ proof by cases 1,1a-2a,1b-2b

\end{description}

\item[(4):]  $((A \wedge B) \vee (B \wedge C)) \rightarrow B$ deduction 1-3

\end{description}

Next, we verify the classical rule of {\em constructive dilemma\/} in two different ways.

The rule to be verified is

$$\begin{array}{c}

P \vee Q \\

P \rightarrow R \\

Q \rightarrow S \\ \hline 

R \vee S

\end{array}$$

This should be extremely believable!

\newpage

The first proof:

\begin{description}

\item[(1):]  $P \vee Q$  premise

\item[(2):]  $P \rightarrow R$ premise

\item[(3):]  $Q \rightarrow S$  premise

\item[Goal:]  $R \vee S$

We prove this by cases on (1).

\item[Case 1:]

\begin{description}

\item

\item[Assume(1a):]  $P$

\item[Goal:]  $R \vee S$

\item[(2a):]  $R$ m.p. lines 2,1a

\item[(3a):]  $R \vee S$ addition line 2a

\end{description}


\item[Case 2:]

\begin{description}

\item

\item[Assume(1b):]  $Q$

\item[Goal:]  $R \vee S$

\item[(2b):]  $S$ m.p. lines 3,1b

\item[(3b):]  $R \vee S$ addition line 2b

\end{description}

\end{description}

\newpage

The second proof:

\begin{description}

\item[(1):]  $P \vee Q$  premise

\item[(2):]  $P \rightarrow R$ premise

\item[(3):]  $Q \rightarrow S$  premise

\item[Goal:]  $R \vee S$

We  prove this by alternative elimination.

\begin{description}

\item[Assume(4):] $\neg R$

\item[Goal:]  $S$

\item[(5):]  $\neg P$ modus tollens 4,2

\item[(6):]  $Q$ disjunctive syllogism (d.s.) 1,5

\item[(7):]  $S$ m.p. 6,3

\end{description}

\item[(8):]  $R \vee S$ alternative elimination 4-7

\end{description}

\newpage

The full Theorem which justifies the rules of alternative elimination and disjunctive syllogism, stating the equivalence of a disjunction with a certain implication.  Notice that since we are using this to justify a.e. and d.s., we will not use a.e. or d.s. in the proof.

\begin{description}

\item[Theorem:]  $P \vee Q \leftrightarrow \neg Q \rightarrow P$

\begin{description}

\item[Part I:]

\begin{description}

\item[Assume (1):]  $P \vee Q$

\item[Goal:]  $\neg Q \rightarrow P$

\begin{description}

\item[Assume (2):]  $\neg Q$

\item[Goal:]  $P$

We will prove this by contradiction.

\begin{description}

\item[Assume (3):]  $\neg P$

\item[Goal:]  $\perp$

Now we will prove $\perp$ by cases using (1).

\begin{description}

\item [Case I on (1):  assume (1a):]  $P$

(2a)  $\perp$  contradiction 1a,3

\item[Case II on (1):  assume (1b):]  $Q$

(2b) $\perp$  contradiction 2, 1b

\end{description}

[(4):]  $\perp$  proof by cases, 1, 1a-2a, 1b-2b.

\end{description}

[(5):]  $P$  reductio ad absurdum 3-4

\end{description}

[(6):]  $\neg Q \rightarrow P$  deduction 2-6

\end{description}

Part II is on the next page

\newpage

\item[Part II:]

\begin{description}

\item[Assume (7):]  $\neg Q \rightarrow P$

\item[Goal:]  $P \vee Q$

With just the basic rules, we have no way to prove $P$ or $Q$ here.  So we use
reductio.

\begin{description} 

\item[Assume (8):] $\neg(P \vee Q)$

\item[Goal:]  $\perp$

\item[Goal:]  $Q$ (this will give us a contradiction by giving $P \vee Q$:  we prove it
by reductio.)

\begin{description}

\item[Assume (9):]  $\neg Q$

\item[Goal:]  $\perp$

\item[(10):]  $P$ mp 9,7

\item[(11):]  $P \vee Q$ addition 10

\item[(12):]  $\perp$  contra 11,8


\end{description}

\item[(13):]  $Q$ reductio 9-12

\item [(14):]  $P \vee Q$  addition 13

\item[(15):]  $\perp$ contra 14,8



\end{description}

\item[16:]  $P \vee Q$ reductio 8-15
\end{description}

\item[The theorem:]  biconditional introduction 1-6, 7-16

\end{description}

\end{description}

The rule has another flavor, supported by another theorem:

\begin{description}

\item[Theorem:]  $P \vee Q \leftrightarrow \neg P \rightarrow Q$

\item[Proof (left to the reader):]  You could write a proof of this very close to the one above.  Or, you could prove it from the previous theorem and an application of the contrapositive theorem and double negation.

\end{description}

\newpage

I got in trouble in class doing the next theorem.  This expresses what we know about the negation of an implication.

\begin{description}

\item[Theorem:]  $\neg(P \rightarrow Q) \leftrightarrow P \wedge \neg Q$

\begin{description}

\item[Part I:]

\begin{description}

\item[Assume (1):]  $\neg (P \rightarrow Q)$

\item[Goal:]  $P \wedge \neg Q$

There is no need for introduction of assumptions in a proof of an and statement.  Indentation is optional.  Prove each part of it then use the rule of conjunction.

\item[Goal 1:]  $P$

Prove this by reductio.

\begin{description}


\item[Assume (2):]  $\neg P$

\item[Goal:] $\perp$

\item[Goal:]  $P \rightarrow Q$

I'll do this more tidily than I did in class.  I'll use indirect proof!

\begin{description}

\item[Assume (3):]  $\neg Q$

\item[Goal:]  $\neg P$

\item[(4):]  $\neg P$  copied from (2)


\end{description}

\item[(5):]  $P \rightarrow Q$  indirect proof, 3-4

\item[(6):]  $\perp$  contra 5,1

\end{description}

\item[(7):]  $P$  reductio 2-6
\item[Goal 2:]  $\neg Q$

\begin{description}

\item[Assume (8):]  $Q$

\item[Goal:]  $\perp$

\item[Goal:]  $P \rightarrow Q$, to get a contradiction with line 1.

\begin{description}

\item[Assume (9):]  $P$

\item[Goal:] $Q$

\item [(10):]  $Q$ copied from line 8

\end{description}

\item[(11):]  $P \rightarrow Q$  deduction 9-10

\item[(12):]  $\perp$  contra 11,1

\end{description}

\item[(13):]  $\neg Q$  neg intro 8-12

\item[(14):]  $P \wedge \neg Q$  conjunction 7,13

\end{description}

\item[Part II:]

\begin{description}

\item[Assume (15):]  $P \wedge \neg Q$

\item[Goal:]  $\neg (P \rightarrow Q)$

\begin{description}

\item[Assume (16):]  $P \rightarrow Q$

\item[Goal:]  $\perp$

\item[(17):]  $P$ simp 15

\item[(18):]  $\neg Q$ simp 15

\item[(19):]  $Q$ mp 17,16

\item[(20):]  $\perp$  contra 18,19

\end{description}

\item[(21):]  $\neg(P \rightarrow Q)$ neg intro 16-20

\end{description}



\end{description}

\item[(22):]  the theorem:  biconditional introduction 1-14, 15-21

\end{description}

\newpage

\section{Exercises}

This is the second set of exercises, assigned 9/13/2021 and due 9/22/2021 (giving a little extra time to think about it and ask me questions, not, one hopes, to put it off.).

\begin{enumerate}

\item Prove $((P \vee \neg Q) \wedge (\neg P \vee R)) \rightarrow (Q \rightarrow R)$

Hint:  this starts with the usual setup for an implication, then repeatedly uses disjunctive syllogism.

\item Verify the rule of {\em destructive dilemma\/}

$$\begin{array}{c}

P \rightarrow R\\

Q \rightarrow S \\

\neg R \vee \neg S \\ \hline

\neg P \vee \neg Q

\end{array}$$

I give you the first few lines

\begin{description}

\item[(1):]  $P \rightarrow R$

\item[(2):]  $Q \rightarrow S$

\item[(3):]  $\neg R \vee \neg S$

\item[Goal:]  $\neg P \vee \neg Q$

\end{description}

Hints:  you could prove this either by cases or by alternative elimination.  If you prove it by alternative elimination, do notice
that the hypothesis will be $\neg\neg P$ not $\neg P$ (and you can get $P$ from this right away).  No matter which way you prove it,
you will definitely want to use the rule of modus tollens one or more times.  This is very similar to the constructive dilemma proof in either case, but just a little more indirect.

\item  Prove $$\neg(P \vee Q) \leftrightarrow (\neg P \wedge \neg Q)$$.  You may {\em not\/} use the de Morgan laws here:  that is what you are trying to prove.  You need to use the proof strategies in this document.  I will do the other de Morgan law on Wednesday to illustrate some points that will be needed to complete this proof.

There is a new fourth exercise on the next page!

\item  Verify that the rule of destructive dilemma is valid by the truth table method.  I promise not to assign you another 16 line truth table.  An essential part of the answer is a statement in English as to what facts about
rows and/or columns in the truth table show that the rule is valid.   This follows on exercises 6 and 7 in homework 1, but is a bit larger, and hopefully will take a little of the shine off of using truth tables!

\end{enumerate}


\section{Example (one of de Morgan's laws)}

\begin{description}

\item[Theorem:]  $$\neg(P \wedge Q) \leftrightarrow (\neg P \vee \neg Q)$$

\item[Part I:]

\begin{description}

\item

\item[Assume(1):]  $\neg(P \wedge Q)$

\item[Goal:]  $\neg P \vee \neg Q$

We will use the new alternative elimination strategy to prove this disjunction.

\begin{description}

\item[Assume(2):]  $\neg \neg P$

\item[Goal:]  $\neg Q$

\begin{description}

\item[Assume (3):]  $Q$

\item[Goal:]  $\perp$

\item[(4):]  $P$ double negation elimination line 2

\item[(5):]  $P \wedge Q$ conjunction lines 4,3

\item[(6):]  $\perp$  contradiction lines 1,5

\end{description}

\item[(7):]  $\neg Q$  neg intro, 3-6

\end{description}

\item[(8):]  $\neg P \vee \neg Q$ alternative elimination, 2-7

\end{description}

Part II of the proof is on the next page.

\newpage

\item[Part II:]

\begin{description}

\item

\item[Assume(9):]  $\neg P \vee \neg Q$

\item[Goal:]  $\neg(P \wedge Q)$

\begin{description}

\item[Assume(10):] $P \wedge Q$

\item[Goal:]  $\perp$

We have unpacked things as far as we can.  The next thing to do is to try proof
by cases on line 9.

\item[Case 1 (from (9):]  

\begin{description}

\item

\item[Assume(9a):]  $\neg P$

\item[Goal:]  $\perp$

\item[(10a):]  $P$ simp 10

\item[(11a):]  $\perp$ contradiction lines 9a,10a

\end{description}

\item[Case 2 (from (9):]

\begin{description}

\item

\item[Assume(9b):] $\neg Q$

\item[Goal:]  $\perp$

\item[(10b):]  $Q$ simp 10

\item[(11b):]  $\perp$ contradiction lines 9b,10b

\end{description}

\item[(12):]  $\perp$ proof by cases, 9, 9a-11a, 9b-11b

\end{description}

\item[(13):]  $\neg(P \wedge Q)$  neg intro 10-12

\end{description}

\item[(14):]  The theorem, by biconditional introduction, 1-8, 9-13

\end{description}

I thought I was going to use {\em reductio ad absurdum\/} in this but I didn't have to.

\newpage

\begin{comment}

\section{Solutions to the first set of Exercises}

Write formal proofs in the style given above of each theorem.

\begin{enumerate}

\item $(A \wedge B) \rightarrow (B \wedge A)$

\begin{description}

\item

\begin{description}

\item[Assume(1):]  $A \wedge B$

\item[Goal:]  $B \wedge A$

\item[(2):]  $B$ simp 1

\item[(3):]  $A$ simp 1

\item[(4):]  $B \wedge A$ conjunction 2,3



\end{description}

\item[(4):]  $(A \wedge B) \rightarrow (B \wedge A)$  deduction, lines 1-4

\end{description}

\item $(A \wedge (A \rightarrow B)) \rightarrow B$
\begin{description}

\item
\begin{description}

\item[Assume(1):]  $A \wedge (A \rightarrow B)$

\item[Goal:]  $B$

\item[(2):]  $A$ simp 1

\item[(3):]  $A \rightarrow B$  simp 1

\item[(4):]  $B$ m.p. 2,3

\end{description}

\item[(5):]  $(A \wedge (A \rightarrow B)) \rightarrow B$ deduction lines 1-4

\end{description}

\item $(A \rightarrow (B \wedge C)) \rightarrow (A \rightarrow C)$

\begin{description}
\item

\begin{description}

\item[Asssume(1):]  $A \rightarrow (B \wedge C)$

\item[Goal:]  $A \rightarrow C$

\begin{description}

\item[Assume(2):]  $A$

\item[Goal:]  $C$

\item[(3):]  $B \wedge C$ m.p. 1,2

\item[(4):]  $C$ simp 3

\end{description}

\item[(5):]  $A \rightarrow C$ deduction 2-4

\end{description}

\item[(6):]   $(A \rightarrow (B \wedge C)) \rightarrow (A \rightarrow C)$ deduction 1-5

\end{description}

\newpage

\item $((A \rightarrow B) \wedge (B \rightarrow C) \wedge (C \rightarrow D)) \rightarrow (A \rightarrow D)$

\begin{description}

\item[Assume(1):]  $(A \rightarrow B) \wedge (B \rightarrow C) \wedge (C \rightarrow D)$

\item[Goal:]  $A \rightarrow D$

\begin{description}

\item

\begin{description}
\item[Assume(2):]  $A$

\item[Goal:]  $D$

\item[(3):]  $A \rightarrow B$ simp 1

\item[(3a):]  $(B \rightarrow C) \wedge (C \rightarrow D)$ [quite optional]

If you felt the need to write a line like this and use simp3a instead of simp 1 in lines 5 and 7, you might have promise as a logician!  Using simp without comment in conjunctions of three or more sentences is fine in this class.

\item[(4):]  $B$ m.p. 1,3

\item[(5):]  $B \rightarrow C$  simp 1

\item[(6):]  $C$ m.p. 4,5

\item[(7):]  $C \rightarrow D$ simp 1

\item[(8):]  $D$ m.p. 6,7

\end{description}

\item[(9):]  $A \rightarrow D$ deduction 2-8

\end{description}

\item[(10):]  $((A \rightarrow B) \wedge (B \rightarrow C) \wedge (C \rightarrow D)) \rightarrow (A \rightarrow D)$ deduction 1-9

\end{description}

\newpage

\item $(A \vee B) \rightarrow (B \vee A)$  Hint: you will want to prove this by cases on the hypothesis $A \vee B$.  Notice that we do have rules which allow deduction
of $B \vee A$ from $A$ and from $B$ (the rule of addition).

\begin{description}

\item

\begin{description}
\item[Assume(1):]  $A \vee B$

\item[Goal:]  $B \vee A$

prove by cases on (1)

\item[Case 1 (on (1)):]  

\begin{description}

\item

\item[Assume(1a):]  $A$

\item[Goal:]  $B \vee A$

\item[(2b):]  $B \vee A$  addition 1a

\end{description}

\item[Case 2 (on (1)):]  

\begin{description}

\item

\item[Assume(1b):]  $B$

\item[Goal:]  $B \vee A$

\item[(2b):]  $B \vee A$  addition 1b

\end{description}

\item[(3):]  $B \vee A$  proof by cases, 1, 1a-2a, 1b-2b

\end{description}
\item[(4):]  $(A \vee B) \rightarrow (B \vee A)$  deduction lines 1-3

\end{description}

Here is another proof using the additional rules introduced more recently.  I don't expect anyone to come up with this, but if they do it is acceptable.

\begin{description}

\item[Prove:]  $(A \vee B) \rightarrow (B \vee A)$

\begin{description}
\item[Assume(1):] $A \vee B$

\item[Goal:]  $B \vee A$

try proving this by alternative elimination

\begin{description}

\item[Assume(2):]  $\neg B$

\item[Goal:]  $A$

\item [(3):]  $A$ disjunctive syllogism 1,2

\end{description}

\item[(4):]  $B \vee A$ alternative elimination 2-3

\end{description}

\item[(5):]  $(A \vee B) \rightarrow (B \vee A)$  deduction lines 1-4



\end{description}

\item Use the truth table method to verify that the rule of {\em modus tollens\/}

$$\begin{array}{c}

A \rightarrow B \\ 

\neg B \\ \hline

\neg A \\

\end{array}$$

is a valid argument.  Be sure to include a discussion in English of the properties of rows and/or columns of the truth table which show this.

$$\begin{array}{c|cc|cc|c}

 & A & B & A \rightarrow B & \neg B & \neg A \\ \hline
(1) & T & T & T & F & F \\
(2) & T & F & F & T & F \\
(3) & F & T & T & F & T \\
(4) & F & F & T & T & T \\

\end{array}$$

The required comments in English:  the only line in which both premises are true is line 4, and in that line the conclusion is also true, so the argument is valid.

\item Use the truth table method to show that this argument (I think it is called {\em denying the antecedent\/}) is invalid.

$$\begin{array}{c}

A \rightarrow B \\ 

\neg A \\ \hline

\neg B \\

\end{array}$$

Be sure to include a discussion in English of the properties of rows and/or columns of the truth table which show this.

$$\begin{array}{c|cc|cc|c}

 & A & B & A \rightarrow B & \neg A & \neg B\\ \hline
(1) & T & T & T & F & F \\
(2) & T & F & F & F & T \\
(3) & F & T & T & T & F \\
(4) & F & F & T & T & T \\

\end{array}$$

required English comments:  In line 3, the premises are both true and the conclusion is false.  So the argument is invalid.

\end{enumerate}
\end{comment}

\begin{comment}


\section{Solutions to second exercise set}

This is the second set of exercises, assigned 1/29/2018 and due next Monday (yes, I am giving a little extra time).

\begin{enumerate}

\item Prove $((P \vee \neg Q) \wedge (\neg P \vee R)) \rightarrow (Q \rightarrow R)$

Hint:  this starts with the usual setup for an implication, then repeatedly uses disjunctive syllogism.

\begin{description}

\item

\begin{description}

\item[Assume:]  $((1)P \vee \neg Q) \wedge (2)(\neg P \vee R)$

Just to mix it up, I'm using the style which I allow of numbering the parts of an and statement separately so that the rule of simplificaition can be side-stepped.

\item[Goal:] $Q \rightarrow R$

\begin{description}
\item[Assume(3):]  $Q$

\item[Goal:]  $R$

\item[(4):]  $P$ d.s. 1,3

\item[(5):]  $R$  d.s 2,4

\end{description}

\item[(6):]  $Q \rightarrow R$ deduction 3-5

\end{description}

\item[(7):]  $((P \vee \neg Q) \wedge (\neg P \vee R)) \rightarrow (Q \rightarrow R)$  deduction 1-6

\end{description}

\newpage

\item Verify the rule of {\em destructive dilemma\/}

$$\begin{array}{c}

P \rightarrow R\\

Q \rightarrow S \\

\neg R \vee \neg S \\ \hline

\neg P \vee \neg Q

\end{array}$$

I give you the first few lines

\begin{description}

\item[(1):]  $P \rightarrow R$

\item[(2):]  $Q \rightarrow S$

\item[(3):]  $\neg R \vee \neg S$

\item[Goal:]  $\neg P \vee \neg Q$

\end{description}

Hints:  you could prove this either by cases or by alternative elimination.  If you prove it by alternative elimination, do notice
that the hypothesis will be $\neg\neg P$ not $\neg P$ (and you can get $P$ from this right away).  No matter which way you prove it,
you will definitely want to use the rule of modus tollens one or more times.  This is very similar to the constructive dilemma proof in either case, but just a little more indirect.

I'll prove it by alternative elimination.

\begin{description}

\item[(1):]  $P \rightarrow R$  premise

\item[(2):]  $Q \rightarrow S$  premise

\item[(3):]  $\neg R \vee \neg S$ premise

\item[Goal:]  $\neg P \vee \neg Q$

\begin{description}

\item[Assume(4):]  $\neg\neg P$

\item[Goal:]  $\neg Q$

\item[(5):]  $P$ dne line 4

\item[(6):]  $R$ modus ponens 5,1

\item[(7):]  $\neg S$  d.s.  6,3

\item[(8):]  $\neg Q$  modus tollens 7,2



\end{description}

\item[(9):]  $\neg P \vee \neg Q$  alternative elimination 4-8

\end{description}
\newpage

\item  Prove $$\neg(P \vee Q) \leftrightarrow (\neg P \wedge \neg Q)$$.  You may {\em not\/} use the de Morgan laws here:  that is what you are trying to prove.  You need to use the proof strategies in this document.  I will do the other de Morgan law on Wednesday to illustrate some points that will be needed to complete this proof.

\begin{description}

\item[Part I:]

\begin{description}

\item

\item[Assume(1):]  $\neg(P \vee Q)$

\item[Goal:] $\neg P \wedge \neg Q$

The proof of this goal simply breaks into two parts.  First prove $\neg P$, then prove $\neg Q$.
No assumptions or indentation.

\item[Part Ia:]  Prove $\neg P$

\begin{description}
\item[Assume(2):]  $P$

\item[Goal:]  $\perp$

\item[(3):] $P \vee Q$  addition, 2

\item[(4):]  $\perp$ contradiction 1,3

\end{description}

\item[(5):]  $\neg P$ neg intro 2-4
\item[Part Ib:]  Prove $\neg Q$
\begin{description}
\item[Assume(6):]  $Q$

\item[Goal:]  $\perp$

\item[(7):] $P \vee Q$  addition, 6

\item[(8):]  $\perp$ contradiction 1,7

\end{description}
\item[(9):]  $\neg Q$ neg intro 6-8

\item[(10):]  $\neg P \wedge \neg Q$  conjunction 5,9
\end{description}

Part II is on the next page

\newpage

\item[Part II:]

\begin{description}

\item[Assume(11):]  $\neg P \wedge \neg Q$

\item[Goal:]  $\neg(P \vee Q)$

\begin{description}

\item[Assume(12):]  $P \vee Q$

\item[Goal:]  $\perp$

\item[(13):]  $\neg P$ simp 11

\item[(14):]  $Q$  ds 12,13

\item [(15):]  $\neg Q$  simp 11

\item[(16:]  $\perp$  contradiction 14,15

\end{description}

\item[(17):]  $\neg(P \vee Q)$ neg intro 12-16

\end{description}

\item[18:]  The theorem:  biconditional introduction, 1-10, 11-18.

\end{description}

\newpage

\item  Verify that the rule of destructive dilemma is valid by the truth table method.  I promise not to assign you another 16 line truth table.  An essential part of the answer is a statement in English as to what facts about
rows and/or columns in the truth table show that the rule is valid.   This follows on exercises 6 and 7 in homework 1, but is a bit larger, and hopefully will take a little of the shine off of using truth tables!

$$\begin{array}{c|cccc|ccc|c}

& P & Q & R & S & P \rightarrow R & Q \rightarrow S & \neg R \vee \neg S & \neg P \vee \neg Q \\ \hline

1& T& T & T & T & T & T & F & F\\ \hline
2& T& T & T & F & T & F & T & F\\ \hline
3& T& T & F& T & F & T & T & F\\ \hline
4& T& T & F & F & F& F & T & F\\ \hline
5& T& F& T & T & T & T & F & T\\ \hline
6& T& F & T & F & T & T & T & T\\ \hline
7& T& F & F & T & F & T & T & T\\ \hline
8& T& F & F & F & F& T & T & T\\ \hline
9& F& T & T & T & T & T & F & T\\ \hline
10& F& T & T & F & T & F & T & T\\ \hline
11& F& T & F & T & T & T & T & T\\ \hline
12& F& T & F & F & T & F & T & T\\ \hline
13& F& F & T & T & T & T & F & T\\ \hline
14& F& F & T & F & T & T & T & T\\ \hline
15& F& F & F & T & T & T & T & T\\ \hline
16& F& F & F & F & T & T & T & T\\ \hline

\end{array}$$

Lines 6,11,14,15,16 are the lines in which all the premises are true.  In each of these lines the conclusion is also true, so the argument is valid.

\end{enumerate}

\newpage

\end{comment}

\section{The Universal and Existential Quantifiers}

Up until now, we have been representing simple sentences by letters, because we haven't been concerned about their internal structure.

Of course, an English sentence not mortared together with words like ``and", ``or", or ``if" does have internal features, and these are relevant to reasoning.  An English sentence has a subject and a predicate, and perhaps a direct object.  Some have more structure than this, but this is enough to go on for our purposes.

We will write a sentence with a predicate $P$ and a subject $x$ in the schematic form $P(x)$ (if $P$ stands for ``$\ldots$ is prime" and $x$ stands for 2, then $P(x)$ stands for ``2 is prime").  We note that any statement about an object $x$, however complicated, might be denoted for us by the schematic $P(x)$.

We will write a sentence relating two objects $x$ and $y$ in the schematic for $x \, R \, y$.  The predicate $R$ in this case (in English terms, a transitive verb) we might call a ``logical relation".  Again, $x\,R\,y$ might stand for a very complicated sentence which says something about a relation between $x$ and $y$.  A very simple example is $j$ standing for ``John", $m$ standing for ``Mary", and $j\,L\,m$ standing for ``John loves Mary".

As soon as we admit that simple sentences are {\em about\/} things, we find another pair of logical operations.  Like our earlier menagerie of operations, these are forms of expression which are supported by English and other natural languages.

If $P(x)$ is any sentence about $x$, and $A$ is a set, we write $(\forall x \in A:P(x))$ to mean ``for all $x$ in the set $A$, $P(x)$ is true".
We can express this in other ways in English.  We can say ``for any $x\ldots$", ``for each $x\ldots$".

When the domain $A$ over which the variable is to range is understood from context, we may write
$(\forall x:P(x))$ without explicit reference to the domain of the variable.

An English subject or object of the form ``All men",  ``Each wombat", ``Any prime number" signals the presence of a universal quantifier.
When several of these sorts of subject appear in a sentence, we usually introduce the quantifiers in the same order as the subjects or objects
appear in the sentence.  We will give an example below.

``All men are mortal" expands to ``If $x$ is a man, then $x$ is mortal", but in fact there is more than this.  It is really ``For all $x$, if $x$ is a man then $x$ is mortal".  If we let $H$ be the set of human beings (any set including all men would do), this can be read as $(\forall x \in H:x$ is a man $\rightarrow x$ is mortal).  This analysis is very close to what we did already earlier in the book, but here we are being more explicit about the quantifier.

If $P(x)$ is any sentence about $x$, and $A$ is a set, we write $(\exists x \in A:P(x))$ to mean ``For some $x$, $P(x)$", or ``There is an $x$ such that $P(x)$, or ``There exists an $x$ such that $P(x)$".

Again, when the domain $A$ over which the variable $x$ is intended to range is understood from context, we may write 
$(\exists x:P(x))$

An English subject or object of the form ``Some men",  ``A wombat", ``At least one prime number" signals the presence of an existential quantifier.
When several of these sorts of subject appear in a sentence, we usually introduce the quantifiers in the same order as the subjects or objects
appear in the sentence.  We will give an example below.

Multiple universal quantifiers may appear in the same sentence.  The commutative law of addition, conventionally written $x+y=y+x$, really means
$(\forall x \in {\mathbb R}:(\forall y \in {\mathbb R}: x+y=y+x))$.  The order of the quantifiers doesn't matter:$(\forall y \in {\mathbb R}:(\forall x \in {\mathbb R}: x+y=y+x))$ says the same thing.  This can be abbreviated $(\forall x,y\in {\mathbb R}:x+y=y+x)$ and similarly we could write $(\forall x,y,z\in {\mathbb R}:(xy)z=x(yz))$ to express the associative law of multiplication.  Multiple existential quantifiers are similarly indifferent to order and can be abbreviated similarly.

When quantifiers are mixed, their order matters.  Here is an example in English (which is also the promised illustration of how to tease English sentences into quantifier notation).

``Everybody loves somebody" can be more precisely phrased ``Every human being $x$ loves some human being $y$".  The quantifiers can be pulled to the front in order.  First we say $(\forall x \in H:$  $x$ loves some human being $y$).  Then we pull the second quantifier to the front (but still after and inside the scope of the first one):  $(\forall x \in H:(\exists y \in H:$ $x$ loves $y$))

We all know that ``John loves Mary", and ``Mary is loved by John", mean the same thing.  But ``Somebody is loved by everybody" does not mean the same thing as ``Everybody loves somebody".  We do the analysis:
\begin{enumerate}
\item Some human being $y$ is loved by every human being $x$ [It doesn't matter what letters we choose, and this will turn out to be the right choice of letters to illustrate an important point].

\item $(\exists y \in H:$ $y$ is loved by every human being $x$)

\item $(\exists y\in H:(\forall x \in H:$ $y$ is loved by $x$))

\item And of course this means the same thing as \begin{center}$(\exists y\in H:(\forall x \in H:$ $x$ loves $y$))\end{center}
\end{enumerate}

The only difference between the sentences is the order of the quantifiers.  But they mean different things.

The second one makes a stronger claim.  It says that there is a particular $y$ (call it $c$) such that $(\forall x:x$ loves $c)$.  So John loves $c$, Mary loves $c$, Ahmed loves $c$, Fatima loves $c$, and so on through everyone in the human race...even $c$ loves $c$!

The first sentence doesn't say this.  Suppose the whole human race was divided into married couples, each of whom loved their spouse and no one else.  There would then be no $c$ such as is asserted to exist by the other sentence.  But for each human being $a$, it would be true that $(\exists y:y$ loves $a$):  because if $a$ is married to $b$, $a$ loves $b$ (and no one else, in my model situation).

It is useful to notice that the sentence $(\forall x\in A:P(x))$ is not about any particular $x$.  This is clear, since $x$ ranges over all the elements of $A$.
It might be less obvious that $(\exists x\in A:P(x))$ is not about any particular element $x$ of $A$.  After all, the sentence $(\exists x:2x+1=7)$ does seem to be about 3, which makes it true.  But it is important to note that there isn't necessarily a unique witness to the truth of an existential sentence, and moreover, we may know that such a sentence is true without knowing who or what makes it true (so we certainly aren't referring to them).
$(\exists x,y\in {\mathbb Z}:xy=60)$ is  not about any particular pair of numbers (there are many pairs which make it true).

As I have observed before, we seldom negate complicated sentences explicitly in English.  Instead, we tend to move the negation to the predicate and carry out more or less complicated logical operations on the sentence during this process to make it work.  $\neg$(roses are red and violets are blue) would normally be expressed as ``roses are not red {\em or\/} violets are not blue".  Similarly, $\neg$(All men are mortal) says
``Some man is not mortal".  The logical transformation takes $\neg(\forall x\in A:P(x))$ to $(\exists x \in A:\neg P(x)$, and in fact we have already discussed this, though without mentioning quantifiers.  The way to falsify a universal statement is to find a counterexample.   Similarly
$\neg$(Some girls have blue hair) is transformed to ``Each girl does not have blue hair!" (There is some tension in English usage about how a statement of this form is to be read, which seems to be less if I say each rather than all or every:  there is no such tension in mathematics).  In symbols, $\neg(\exists x \in A:P(x))$ is equivalent to $(\forall x \in A:\neg P(x))$.

The impression that $(\exists x \in A:P(x))$ is about a specific element of $A$ might be dispelled or diminished by considering that
$$(\exists x \in A:P(x)) \equiv \neg\neg (\exists x \in A:P(x)) \equiv \neg(\forall x\in A : \neg P(x)).$$

There are {\em rules\/} about proving statements with universal and existential quantifiers, and about using assumptions or theorems with such quantifiers.

To prove $(\forall x \in A:P(x))$, we argue in this way:

\begin{description}
\item[Prove:]  $(\forall x \in A:P(x))$

\begin{description}

\item[Let:]  $a$ be chosen arbitrarily (this should be a new letter with no prior meaning) and assume (1) $a \in A$
\item[Goal:]  $P(a)$

\item[various intervening proof steps:] $\vdots$

\item[(n):]  $P(a)$

\end{description}

\item[(n+1):]  $(\forall x:P(x))$ universal generalization, lines 1-n

\end{description}

This rule might look suspiciously like our strategy for proving implications.  The reason it works is that we do not allow ourselves any prior assumptions about $a$ other than that it is an element of $A$:  if we can show that a completely anonymous element of $A$ about which we know nothing satisfies $P(a)$, then clearly for every $x\in A$, $P(x)$ is true.

The rule for using a universal hypothesis is lovely and simple

$$\begin{array}{c}

(\forall x \in A:P(x)) \\

t \in A \\ \hline

P(t)
\end{array}$$

This is called {\em universal instantiation\/}.  The name $t$ may name any specific element of $A$, including ones about which you have lots of information.  If all natural numbers have prime factors, it follows that 143 has a prime factor.

The rule for proving an existantial statement is simple, and can be expressed as a valid argument form:

$$\begin{array}{c}

t \in A \\

P(t) \\ \hline

(\exists x:P(x))
\end{array}$$

where $t$ is any name at all.  Since 121 is odd and a perfect square, it follows that $(\exists x \in {\mathbb N}:$  $x$ is an odd perfect square).  This is the rule of {\em existential instantiation\/}.
\newpage
This can be expressed as a strategy:

\begin{description}
\item[Prove:] $(\exists x \in A:P(x))$

\item[Goal:]  {\bf Find} a $t$ for which we can prove $P(t)$

This is open ended...we have to figure out what will work.  As soon as we show $P(t)$ for some specific $t$ we are done.

\end{description}

Finally, the strategy for {\em using\/} an existential hypothesis is a bit trickier.

\begin{description}

\item[(n):]  $(\exists x \in A:P(x))$

\item[Goal:] $C$

\begin{description}
 \item[Let]  $w$ be an arbitrary witness to line $n$:  we assume (n+1) $w \in A$ and (n+2) $P(w)$ [and we have never heard of $w$ before and use no other assumptions about it].

\item[intervening proof steps:]  $\vdots$

\item[(m):]  $C$

\end{description}

\item[(m+1):]  $C$ witness introduction line n and lines n+1-m

\end{description}

In the rules of universal generalization and witness introduction, the assumptions and the ``arbitrary'' objects introduced in the indented blocks should not be mentioned again outside those blocks.

I'm not planning to assign formal proofs using these rules, but I will use something like this format in proofs that I do on the board.  When you write proofs in English, you should have these thought patterns in your head.  And you do already.  I'll illustrate this by presenting a  proof that the sum of two odd numbers is even, first in an informal way and then in a way which makes use of formal rules for quantifiers explicit.

\newpage

\begin{description}

\item[Prove:]  The sum of any two odd integers is even.

\item[Definitions:]  An integer $a$ is even iff there is an integer $x$ such that $2x=a$.

An integer $a$ is odd iff there is an integer $x$ such that $2x+1=a$.

\item [Proof:]  We first present this as a universal statement involving a conditional:  our goal is to prove that for any integers $x,y$, if $x$ is even and $y$ is even then $x+y$ is even.

\begin{description}

\item [Let] $a,b$ be arbitrarily chosen integers.  \item[Our goal] is to prove that if $a$ is odd and $b$ is odd, then $a+b$ is even.

\begin{description}

\item[Assume] that (1) $a$ is odd and (2) $b$ is odd.

\item[by] (1), we can choose an integer $k$ such that $2k+1=a$

\item[by] (2), we can choose an integer $l$ such that $2l+1=b$

\item[The goal can be restated as]  find an integer $c$ such that $2c=a+b$

\item[compute:]  $a+b = (2k+1) + (2l+1) = 2(k+l+1)$.  $k+l+1$ is an integer by the closure property for integers under addition.  So we can set $c:= k+l+1$ and we have $c$ an integer and $2c=a+b$ as desired.  This establishes that $a+b$ is even.

\end{description}

\item[so we have shown that]  if $a$ is odd and $b$ is odd, then $a+b$ is even,

\item[so we have shown that,] since $a$ and $b$ were chosen arbitrarily, that for any integers $x,y$, if $x$ is even and $y$ is even then $x+y$ is even.

\end{description}

\end{description}



\newpage
\begin{description}
\item[Prove:]  The sum of any two odd integers is even.

\item[The goal rephrased:]  $(\forall x,y \in {\mathbb Z}:$ $x$ is odd $\wedge$ $ y$ is odd $\rightarrow x+y$ is even)

\begin{description}
\item[Let] $a,b \in {\mathbb Z}$ be chosen arbitrarily.

\item[Goal:]  if $a$ is odd and $b$ is odd then $a+b$ is even.

Please recognize the setup for a proof by universal generalization here.

We now use the strategy for proving an implication which we already know.

\begin{description}
\item[Assume that:]  (1) $a$ is odd and (2) $b$ is odd

\item[Goal:]  $a+b$ is even.

We rephrase the goal using the definition of even, with an actual quantifier.

\item[Rewritten Goal:]  $(\exists z \in {\mathbb Z}: 2z = a+b)$

\item[Further rewritten goal:]  {\bf Find} an integer $c$ such that $2c = a+b$.

We now unpack the definition of odd and rephrase our assumptions:

\item[(3):]  $(\exists x \in {\mathbb Z}:a=2x+1)$, by (1) and the definition of odd

\item[(4):]  $(\exists x \in {\mathbb Z}:b=2x+1)$ by (2) and the definition of odd

\begin{description}

\item[Let (5):]  $u$ be an integer such that $a=2u+1$ (witness to (3))

\item[Let (6):]  $v$ be an integer such that $b=2v+1$ (witness to (4))

Though we used the same dummy variable in the statements (3) and (4), when we introduce a witness to
an existential statement it is a new object we know nothing about...so when we introduce two of them we do not assume they are the same!

Our goal is the same

\item[Reminder of Goal:]  Find $c$ such that $2c=a+b$

Now we have done all our setup and the little bit of creativity in this proof happens.

$$a+b = (2u+1) + (2v+1) = 2(u+v+1).$$  $u+v+1$ is an integer by closure.  Let $c$ be $u+v+1$ and we have
$2c=a+b$ for the integer $c$, so (7) $a+b$ is even (because $(\exists z:2z=a+b)$ has been shown by existential instantiation).

\end{description}
(8) $a+b$ is even by witness introduction (even after we forget $u,v$ and our assumptions about them).
\end{description}
(9)  $a$ is odd and $b$ is odd $\rightarrow$  $a+b$ is even by deduction
\end{description}
(10) $(\forall x,y:$ $x$ is odd and $y$ is odd $\rightarrow$ $x+y$ is even by universal generalization.

\end{description}

I do not suggest that you write proofs in this exhausting second way!  Certainly the way that the goal echoes at the end of the rule of witness introduction does not need to be reflected in your proofs in English.  The purpose of presenting the proof in this way is to let you see that the argument as presented more informally above, which is a kind of text you should be able to write after you get through this course, actually used three of the four quantifier strategies, and fairly explicitly!

\section{Homework 18}

This can be turned in up to the final exam.

Write proofs of the following statements in the style of the examples given in class and above.  You do not have to actually write quantifier symbols or explicitly mention quantifier rules (the first style of proof given on p. 48  is fine).

You should however introduce variables appropriately, use the English words for quantifiers where appropriate, and bring out hidden implications.

\begin{enumerate}

\item  The sum of an odd number and an even number is odd.

\item  The product of two odd integers is odd (we did this in class, but it won't hurt you to write it out yourself).

\item  If $d|x$ and $d|y$, then $d|(ax + by)$ [all numbers mentioned being integers]

\item If $a|b$ and $b|c$, then $a|c$ (again, we did this in class, but it will not hurt you to write the proof yourself).


\end{enumerate}


\end{document}
\documentclass[12pt]{article}

\usepackage{amssymb}

\title{Class Lecture Notes for Math 305, Spring 2022}

\author{Dr Holmes}

\begin{document}

\maketitle

These are notes on what I say in class in Math 305.

\tableofcontents


\section{Tuesday, January 11, 2022}

Administrative preliminaries.


I discussed the definitions of ${\mathbb Z}$, ${\mathbb N}$, ${\mathbb Z}^+$: 

${\mathbb Z} = \{\ldots,-2,-1,0,1,2,\ldots\}$, the set of integers;

${\mathbb N}= \{0,1,2,\ldots\}$, the set of natural numbers (there is no general agreement in mathematical literature as to whether 0 is a natural number, but this book includes it), or non-negative integers;

${\mathbb Z}^+ = \{1,2,3,\ldots\}$, the set of positive integers.  In all of these, the use of dots is really cheating:  giving a rigorous definition of these sets is rather difficult, and we appeal instead to your pre-formal understanding of these concepts.

I stated a set of axioms for the integers which I will include here (based on the axioms in the Math 287 book with two alternative approaches to order).

We begin with a set of purely algebraic axioms.  Our variables range over the set $\mathbb Z$ of integers;  we assume special integers 0 and 1 and primitive operations or addition (+) multiplication ($\cdot$) and additive inverse ($-$, used as a prefix unary operator).

\begin{description}

\item[commutative laws:]  For any $x,y \in {\mathbb Z}$, $x+y=y+x$ and $x \cdot y = y \cdot x$.

\item[associative laws:]  For any $x,y,z \in {\mathbb Z}$, $(x+y)+z = x+(y+z)$ and $(x \cdot y)\cdot z = x \cdot(y\cdot z)$.  I should add that we are only allowed to write things like $x+y+z$ or $x \cdot y \cdot z$ because we know these operations are associative.  In proofs in section 1.2 you should write parentheses, and explicitly use the associative laws to move them.

You {\em may\/} use standard order of operations and read $x \cdot y + z$ as meaning $(x \cdot y) + z$ wihtout writing out the parentheses (multiplication binds more tightly than addition, unary minus binds more tightly than either).

\item[distributive law:]  For any $x,y,z \in {\mathbb Z}$, $x\cdot(y+z) = x \cdot y + x \cdot z$.

\item[identity laws:]  For any $x \in {\mathbb Z}$, $x+0=x$ and $x \cdot 1 = x$.  $0 \neq 1$.

\item[multiplicative cancellation:]  For any $x,y,z \in {\mathbb Z}$, if $x \neq 0$ and $x\cdot y = x\cdot z$, then $y=z$.
This amounts to the ability to divide both sides of an equation by the same thing, but we do not have a full division operation in the integers as we do in the rationals or reals.

\end{description}

This is not a full axiomatization of the integers.  Of course, systems like the rationals and the reals which extend the integers
satisfy these axioms, but there are also systems (even ones familiar to you) which satisfy these axioms and are quite different from the integers.  Arithmetic mod $p$ where $p$ is prime satisfies these axioms, and the domain of ``numbers" in mod $p$ arithmetic is finite (the remainders $0,1,\ldots p-1$ mod $p$).

Additional axioms appropriate for the integers which rule out the system described being modular arithmetic are axioms of order.  We present these (just for fun) in two different ways.

We can axiomatize order by introducing the set of positive integers ${\bf Z}^+$ as a primitive notion, providing some of its properties as axioms, and using it to define order relations.

\begin{enumerate}

\item $0 \not\in {\mathbb Z}^+$.

\item  For each $m \in {\mathbb Z}$ with $m \neq 0$ either $m \in {\mathbb Z}^+$ or  $-m \in {\mathbb Z}^+$.

\item For each $m,n \in {\mathbb Z}^+$, we have $m+n \in {\mathbb Z}^+$ and $m\cdot n \in {\mathbb Z}^+$

\item Define $m<n$ as $n+(-m) \in {\mathbb Z}^+$.

\end{enumerate}

This is a very elegant set of axioms, and it should be straightforward for you to see that they are true in the familiar system of integers, but it may be less obvious that they are enough.  This might be a homework exercise.

Here is a more familiar set of axioms for order.  They do follow as consequences of the algebraic and positive integer axioms if we define $<$ as above, but for this approach we ``forget" about ${\bf Z}^+$ and take $<$ as a primitive relation (and we define ${\mathbb Z}^+$ in terms of $<$).

\begin{description}

\item[transitivity:]  For any $m,n,p \in {\mathbb Z}$,  if $m<n$ and $n<p$ then $m<p$.

\item[trichotomy:]  For any $m,n \in {\mathbb Z}$, exactly one of $m<n,m=n,n<m$ is true.

\item[additive monotonicity:]  For any $m,n,p \in {\mathbb Z}$, if $m<n$ then $m+p < n+p$.

\item[multiplicative monotonicity:]  For any $m,n,p \in {\mathbb Z}$, if $p  > 0$ and $m<n$, then $m\cdot p <n\cdot p$.  Our axioms are enough to show that the right things happen if $p$ is zero or negative (that might be a homework exercise).

\item  [definition of positive integers:]  We define ${\mathbb Z}^+$ as $\{x \in {\mathbb Z}:0<x\}$.

\end{description}

I stated the Well-Ordering Principle and proved two sample theorems, ``each positive integer is either even or odd", and ``there is no integer strictly between 0 and 1".

If $S$ is a set of integers, $x$ is a smallest element of $S$ iff $x \in S$ and $(\forall y \in S:x \leq y)$.  You could try proving that a nonempty set with a smallest element has just one smallest element.

\begin{description}

\item[Well-Ordering Principle:]  Any nonempty set $S$ of positive integers has a smallest element.

\end{description}

I proved a couple of sample theorems using the Well-Ordering Principle in class.  Proofs using this principle are usually indirect (proofs by contradiction);  pay attention to the logical structure of what I say.

\begin{description}

\item[Definition:]  An integer $m$ is even iff there is an integer $x$ such that $m=2\cdot x$.  

An integer $m$ is odd iff there is an integer $x$ such that $m=2\cdot x +1$.

\item[Theorem:]  Each positive integer is either even or odd.

\item[Proof:]  Suppose otherwise, so there are integers which are neither even nor odd.  Let $S$ be the set of all integers which are neither even nor odd.  By our assumption, it is nonempty, so by the Well-Ordering Principle it has a smallest element $w$.  This number $w$ will be the smallest integer which is neither even nor odd.

The integer $w$ is not 1, because $1 = 2\cdot 0 +1$ is odd.

So $w-1$ is a positive integer, and because it is less than $w$ it must be either even or odd.

If $w-1=2\cdot x$ is even, then $w=2\cdot x +1$ is odd.

If $w-1=2\cdot x +1$ is odd, then $w = 2 \cdot x +2 = 2 \cdot(x+1)$ is even.

In either case, we get that $w$ is either odd or even, which is a contradiction, so there can be no such $w$ and the theorem must be true.

\item[Observation:]  At a crucial point in the argument above, I cheated (or at least I appealed to your intuition), and the fact is used is important and should be proved.  How do I know that if $w\neq 1$ is a positive integer that $w-1$ is a positive integer?
If we have $w>1$, we do have $w-1>0$.  We need to rule out the possibility that $0<w<1$ (which, since we know what the integers are, is hard to even take into account).

\item[Theorem:]  There is no integer $x$ such that $0<x<1$.

\item[Proof:]  If there is such an integer than the set $S = \{x \in {\mathbb Z}:0<x<1\}$ is nonempty and so by the Well-Ordering Principle has a smallest element $w$.

So we have $0<w<1$.  By multiplicative monotonicity (because $w>0$) we have $0<w^2<w$ and of course
we then have $0<w^2<w<1$.  Using transitivity we see that $0<w^2<1$ and $w^2<w$, so $w^2$ belongs to the set
$S$ but is smaller than $w$, which is a contradiction.


\end{description}

\newpage

\section{Homework 1}

This is being assigned on January 13 and is due January 20.

\begin{enumerate}

\item  Prove all parts of proposition 1.2.8 in Crisman on properties of divisibility (this is on page 4 of Crisman).

\item  Prove by mathematical induction that for every $n \in {\mathbb Z}^+$, $3|(n^3+5n)$.

\item  Prove by mathematial induction that the sum of the first $n$ odd numbers is $n^2$.  Make appropriate use of summation notation.

\item Use the first set of order axioms in these notes (in which the set of positive integers is primitive) along with the algebra axioms to prove at least two of the axioms in the second set of order axioms, in which the less-than relation is primitive (you will need to use the definition of the less-than relation given with the first set of axioms).  Your algebra may be somewhat informal:  your use of order axioms should be careful and explicit.  Extra credit will be rewarded for proving more of the order axioms in the second set.

\end{enumerate}

\newpage

\section{Thursday, January 13, 2022}

We begin with the principle of mathematical induction.

Mathematical induction can be presented as a proof strategy.

\begin{description}

\item[Goal:]  Prove $(\forall n \in {\mathbb Z}^+:P(n))$

\item[basis step:]  Prove $P(1)$

\item[induction step:]

\begin{description}

\item

\item[induction hypothesis:]  


Choose a natural number $k$ arbitrarily.  \newline Assume $P(k)$.

\item[induction goal:]  Prove $P(k+1)$ (under the assumption that $P(k)$ is true).

\end{description}

If you succeed in proving the induction goal, assuming the induction hypothesis, you have proved $(\forall k \in {\mathbb Z}^+:P(k) \rightarrow P(k+1))$.



\end{description}
If you complete both steps, you can conclude $(\forall n \in {\mathbb Z}^+:P(n))$
 by mathematical induction.

One can prove theorems by mathematical induction on ${\mathbb N}$ instead of ${\mathbb Z}^+$:  in this case the basis step is to prove $P(0)$.

We give an example (which also illustrates nice tools for working with summation notation).

\begin{description}
\item[Theorem:]  The sum of the first $n$ squares of positive integers is $\frac{n(n+1)(2n+1)}6$, that is, $$\sum_{i=1}^ni^2 =\frac{n(n+1)(2n+1)}6$$

\item[Proof:]

We prove this by mathematical induction on $n$.

\begin{description}

\item[basis step:]  Prove $\sum_{i=1}^1i^2 = \frac{(1)(1+1)(2\cdot 1+1)}6$

$\sum_{i=1}^1i^2 = 1^2=1= \frac{(1)(1+1)(2\cdot 1+1)}6$ (check)

\item[induction step:]  Choose a positive integer $k$ arbitarily.\newline
Assume (ind hyp) that $\sum_{i=1}^ki^2 = \frac{(k)(k+1)(2k+1)}6$

The induction goal is to prove  $\sum_{i=1}^{k+1}i^2 = \frac{(k+1)(k+2)(2k+3)}6$

Notice that in formulating the induction goal we allowed ourselves to do a little obvious algebra after replacing $k$ with $k+1$.

$\sum_{i=1}^{k+1}i^2  = [\sum_{i=1}^{k}i^2 ]+ (k+1)^2$ (pulling out the last term) $= \frac{(k)(k+1)(2k+1)}6+(k+1)^2$ (by ind hyp: {\bf ALWAYS highlight the use of the inductive hypothesis in any proof by induction}) $= \frac{(k+1)(k)(2k+1) + 6(k+1)(k+1)}6 = \frac{(k+1)((2k^2+k)+(6k+6))}6 = \frac {(k+1)(2k^2+7k+6)}6 = \frac {(k+1)(k+2)(2k+3))}6$ (check)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    


\end{description}

The proof by induction is complete.

\end{description}

I was impressed with success in Math 189 last term at teaching this general approach to proofs of statement involving summations, avoiding dots, which can cause various confusions.

Next, I lectured the equivalence of math induction to the well-ordering principle.

First assume the well-ordering principle and show that math induction follows:

\begin{description}

\item[Given:]

\begin{description}
\item
\item[1.]  $P(1)$

\item[2.] $(\forall k \in {\mathbb Z}^+:P(k) \rightarrow P(k+1))$

\item[3.] the well-ordering principle

\end{description}

\item[Show:]  $(\forall n \in {\mathbb Z}^+:P(n))$

\item[note:]  Convince yourself that if we complete this plan we really have shown that WOP does the work of math induction.

\item[Proof:]  Suppose for the sake of a contradiction that $\neg (\forall n \in {\mathbb Z}^+:P(n))$, so there is some
$x$ a positive integer such that $\neg P(x)$.  Let $S$ be the set of all $x$ such that $\neg P(x)$, which we see is nonempty and so by WOP has a smallest element which we will call $w$.

$w$ is not 1, because we have assumed $P(1)$.  Thus $w>1$ (here we are using the result proved above using WOP that there is no integer strictly between 0 and 1).  Thus $w-1>0$ is a positive integer.  Thus we have $P(w-1)$, because $w$ is the smallest positive integer such that $\neg P(w)$.
But plugging $w-1$ in for $k$ in $(\forall k \in {\mathbb Z}^+:P(k) \rightarrow P(k+1))$ gives $P(w-1) \rightarrow P(w)$, and so since we have
$P(w-1)$ and $P(w-1) \rightarrow P(w)$ we have (by the rule of modus ponens) $P(w)$, but this is a contradiction.

Thus our assumption that $\neg (\forall n \in {\mathbb Z}^+:P(n))$ is incorrect, and we have $(\forall n \in {\mathbb Z}^+:P(n))$


\end{description}

This completes the proof that the well-ordering principle implies the principle of mathematical induction.

Now we argue that the principle of mathematical induction implies the well-ordering principle.

\begin{description}

\item[Given:]

\begin{description}
\item
\item[1.]  $S$ is a nonempty set of positive integers

\item[2.]  the principle of math induction

\end{description}

\item[Show:]  $S$ has a smallest element.

\item[note:]  Convince yourself that this proof plan really does show that the principle of math induction does the work of the well ordering principle, if we can carry it out.

\item[Proof:]  Assume for the sake of a contradiction that $S$ has no smallest element.  We will prove by induction that $S$ is empty, completing the desired contradiction.

We do not prove by induction that for every $n$, $n \not\in S$:  we prove the stronger statement that for every $n$, $(\forall m \in {\mathbb Z}^+: m \leq n \rightarrow m \not\in S)$:   not only is $n$ not in $S$, but no smaller positive integer is in $S$.
We will describe the strategy of strong induction of which this is an example in the last section of the notes for today.

The basis step for the induction is to show $(\forall m \in {\mathbb Z}^+:m \leq 1 \rightarrow m \not\in S)$:  the only positive integer less than or equal to 1 is 1 itself, so all we have
to show is $1 \not\in S$, and this follows from the assumption that $S$ has no smallest element:  if it contained 1, 1 would be its smallest element.

Choose an arbitrary positive integer $k$.  Assume $(\forall m \in {\mathbb Z}^+: m \leq k \rightarrow m \not\in S)$ as our induction hypothesis.  Our induction goal is to show that $(\forall m \in {\mathbb Z}^+: m \leq k+1 \rightarrow m \not\in S)$  If $m$ is an integer $\leq k+1$, it is either
less than $k$ or equal to $k$, in which cases the induction hypothesis tells us that $m \not\in S$, or (final case to be checked) $m>k$.
Now, because there is no integer strictly between 0 and 1, there is also no integer strictly between $k$ and $k+1$ (we could subtract $k$ from it to get between 0 and 1).  Thus, since $m>k$ and $m\leq k+1$, $m$ is simply $k+1$.  We can conclude $k+1 \not\in S$, because if it were in $S$ it would be the smallest element of $S$, since we have shown that nothing less than $k+1$ can belong to $S$.

So we have shown by induction that for every positive integer $n$, $(\forall m \in {\mathbb Z}^+: m \leq n \rightarrow m \not\in S)$, but this immediately implies that for every positive integer $n$, $n \not\in S$, so $S$ is empty, which is a contradiction.

This means that our assumption that $S$ has no smallest element must be false:  it follows from the statements given that $S$ has a smallest element.


\end{description}

This completes the proof that the well-ordering principle follows from the principle of mathematical induction. 

The final topic of this lecture was the method of strong induction.  This is a version of mathematical induction with a stronger hypothesis which is sometimes useful.  We will state it and prove a theorem as an example.  We state but do not prove (it might be fairly easy to see from the proof of equivalence of ordinary math induction and the well-ordering principle) that strong induction is in fact precisely equivalent in strength to ordinary induction.
But it is sometimes much more convenient.

We state strong induction as a strategy of proof.

\begin{description}
\item[Goal:]  Prove $(\forall n \in {\mathbb Z}^+:P(n))$

\item[basis step:]  Prove $P(1)$

\item[induction step:]
\begin{description}

\item
\item[induction hypothesis:]  Let $k$ be an arbitrarily chosen positive integer.  Assume $(\forall m \in {\mathbb Z}^+:m \leq k \rightarrow P(m))$:  instead of assuming just $P(k)$ we assume $P(1), P(2),\ldots,P(k)$.  This is a stronger hypothesis, and this is why we call this method strong induction.

\item[induction goal:]  Prove $P(k+1)$ under the assumption of the inductive hypothesis.

\end{description}

If you succeed in completing the basis and induction steps, you have proved $(\forall n \in {\mathbb Z}^+:P(n))$ by strong induction.

\end{description}

Here is an important example.  (I am not for the moment trying to expound this in terms of product notation as I suggested in class;  I might do it later, but my brain is tired after writing these notes).

\begin{description}

\item[Theorem:]  Each integer $\geq 2$ is a prime or a finite product of primes.

\item[Proof:]

we prove this by strong induction.

The basis step requires us to prove that 2 is a prime or a finite product of primes.  2 is a prime (check).

We choose an arbitrary positive integer $k\geq 2$.  The induction hypothesis will be that for every positive integer $m \leq k$, $m$ is a prime or a product of primes.

The induction goal is to prove that $k+1$ is a prime or a finite product of primes.

By the law of excluded middle either $k+1$ is a prime (in which case we are done, as it is then a prime or a finite product of primes)
or it is composite, in which case there are $a,b$ such that $2 \leq a,b \leq k$ and $ab=k+1$.  Now by inductive hypothesis, each of $a,b$ is either a prime or a finite product of primes, so $ab$ is a finite product of primes.  And this completes the proof of the theorem by strong induction.

\end{description}

\section{Tuesday, January 19, 2022}

Today I talked about the Division Algorithm and the Euclidean Algorithm (plain and extended).  I talked about this off the top of my head, and I owe you a discussion of what this material looks like in Crisman and how it might differ from what I say.

\begin{description}

\item[Theorem (division algorithm):]  For each $a \in {\mathbb Z}$ and $b \in {\mathbb Z}^+$, there are unique determined integers $q$ and $r$ such that $a=bq+r$ and $0 \leq r <b$.

Of course ``$q$" and ``$r$" are hints:  we give these variables these names because they suggest {\em quotient\/} and {\bf remainder\/}.

We prove the theorem using the Well-Ordering Theorem (and it is a positive result, we are not arguing by contradiction!)

\item[Proof:]

Define $S$ as the set $\{a-bq:q \in {\mathbb Z} \wedge a-bq\geq 0\}$.  This is the set of candidates for the remainder $r$, as it were.

It is a set of nonnegative integers, so if it is nonempty it has a least element.

If $a\geq 0$, let $q=0$ and we see that $a-bq=a\geq 0$, so $a \in S$ and $S$ is nonempty.

If $a <0$ let $q=a$ and we see that $a-bq = a-ba=a(1-b)$.  $a$ is negative and $1-b$ is nonpositive (since $b$ is positive), so $a(1-b)$ is nonnegative, and so belongs to $S$, so $S$ is nonempty.

Define $r$ as the smallest element of $S$.  There is a unique $q$ such that $r=a-bq$, so $a=bq+r$.

All that remains is to show $0 \leq r<b$.  We know that $r \geq 0$ because $r \in S$.  Notice that $a-b(q+1)$ must be negative, because
if it were nonnegative it would be an element of $S$ smaller than $r=a-bq$.

$a-b(q+1) = a-bq-b=r-b$ so we have $r-b<0$ so $r<b$ completing the proof.

% typo point for Bridger Lenz

We still need to prove that $q$ and $r$ are uniquely determined.  Suppose that $a=bq-r = bQ-R$ and $0\leq r < R <b$.

Observe that $R-r = b(Q-q)$.  Now $R-r<b$, and the only way for $b(Q-q)<b$ to be true is $Q-q=0$, so $Q=q$.  Then $r=a-bq = a-bQ = R$.

\item[Definition:]  For $a \in {\mathbb Z}$ and $b \in {\mathbb Z}^+$ define $a {\tt div} b$ and $a \,{\tt mod}\, B$ as the unique $q$ and $r$ whose existence is proved by the division algorithm.

\item[Observations:]  Be careful with negative values of $a$.  Notice that while $100 \,{\tt div}\, 3 = 33$ and $100\, \,{\tt mod}\,\, 3 = 1$, it turns out that 
$100\, {\tt div}\, 3 = -34$ and $100 \,\,{\tt mod}\, \,3 = 2$.

It might not be obvious that we can compute \,{\tt mod}\, with a simple calculator.  But we can.  For positive $a$, $a {\tt div} b$ is easy to compute, by computing $\frac ab$ in floating point then dropping what is after the decimal point.  Then $a\, \,{\tt mod}\,\, b=a - b(a\,{\tt div}\,b)$.


\end{description}

Now we prove the Euclidean Algorithm theorem, indicating the procedure for computing the greatest common divisor of two integers, and the extended Euclidean Algorithm theorem which shows that the gcd of two integers is an integer linear combination of those two integers.

\begin{description}

\item[Definition:]  Recall that for integers $a,d$, $d|a$ means that there is an integer $x$ such that $dx=a$.  We say that $d$ is a divisor of $x$.

\item[Definition:]  $d$ is a {\em common divisor\/} of $a$ and $b$ iff $d|a$ and $d|b$.

\item[Lemma:]  For any $a,b$ which are not both zero, there is a greatest common divisor of $a$ and $b$.

\item[Proof:]  If $a$ is not zero, every divisor of $a$ is $\leq |a|$.  Thus if we do not have $a=b=0$, we have an upper bound on common divisors of $a$ and $b$.

Any nonempty set $S$ of integers which has an upper bound $B$ has a greatest element:  this follows from the W.O.P:  the set $S'=\{B-x:x \in S\}$ is a set of nonnegative integers so has a smallest element $B-x$ and this $x$ will be the largest element of $S$.

It follows that the set of common divisors of $a$ and $b$ has a largest element, unless $a=b=0$, in which case all integers fall in the set of common divisors.

\item[Definition:]  Except in the case $a=b=0$, we define ${\tt gcd}(a,b)$, for integers $a,b$ as the greatest common divisor of$a$ and $b$.

\item[Lemma:]   ${\tt gcd}(a,b) = {\tt gcd}(|a|,|b|)$.  This justifies restricting our attention for the rest of this discussion to nonnegative $a,b$.

\item[Lemma:]  ${\tt gcd}(a,0)=a$ if $a>0$.  Obvious.

\item[Lemma:] ${\tt gcd}(a,b) = {\tt gcd}(b,a\,\,{\tt mod}\,\,b)$ if $a>b>0$.

\item[Proof of Lemma:]  Let $a>b>0$.  Let $q=a\,{\tt div}\,b$ and let $r=a\,\,{\tt mod}\,\,b$.

Since $r=a-bq$, any common divisor of $a,b$ is also a divisor of $r$ and so a common divisor of $b,r$.

Since $a=bq+r$, any common divisor of $b,r$ is also a divisor of $a$, and so a common divisor of $a,b$.

It follows that ${\tt gcd}(a,b)$ and ${\tt gcd}(b,a\,\,{\tt mod}\,\,b)$ are respectively the greatest element of one and the same set, so they are equal.

\item[Euclidean Algorithm:]

Let $a>b\geq 0$.  Define a finite sequence $E$ by $E_1=a, E_2=b$ and $E_{i+2}= E_i \,{\tt mod}\, E_{i+1}$ if this is nonzero, and otherwise is undefined.

It is straightforward to see that this is a strictly decreasing sequence of positive integers, and so it must end:  if it were infinite, its range would be a set of positive integers with no smallest elements.

Notice that it is straightforward by the previous Lemma and induction that ${\tt gcd}(E_i,E_{i+1}) = {\tt gcd}(E_1,E_2)$ for each $i$ for which these terms are defined.  If $E_{i+1}$ is the last term, it goes evenly into $E_i$ (that is how the sequence stops) and so $E_{i+1}={\tt gcd}(E_i,E_{i+1}) = {\tt gcd}(E_1,E_2)= {\tt gcd}(a,b)$.  So if one computes this sequence by repeated application of the mod operation, the sequence ends with the greatest common divisor of the two numbers with which you start.

\item[Extended Euclidean Algorithm:]  For any $a>b\geq0$ integers, there are integers $x,y$ such that $ax+by={\tt gcd}(a,b)$ [these integers $x,y$ are not unique, but the procedure we describe will give specifix $x,y$ that work).

\item[Proof:]  Let $a>b>0$.  Compute the sequence $E$ just as above.  

Notice that $E_{i+2}= E_i - (E_i {\tt div}E_{i+1})E_{i+1}$.

Compute two new sequences

$X_1=1, X_2=0, X_{i+2}= X_i - (E_i {\tt div}E_{i+1})X_{i+1}$.
$Y_1=0, Y_2=1, X_{i+2}= Y_i - (E_i {\tt div}E_{i+1})Y_{i+1}$.

Prove by induction that for each $i$ for which the terms of the sequences are defined, $E_i = aX_i + bY_i$:

This is obvious for $i=1,2$:

$aX_1+bY_1 = a1+b0 = a = E_1$.
$aX_2+bY_2 = a0+b1 = a = E_1$.

Suppose it works for $i$ and $i+1$:  then it works for $i+2$:

$aX_{i+2} +bY_{i+2} = a(X_i - (E_i {\tt div}E_{i+1})X_{i+1}) + b(Y_i - (E_i {\tt div}E_{i+1})Y_{i+1}) = (aX_i+bY_i) - (E_i {\tt div}E_{i+1})(aX_{i+1}+bY_{i+1}) =[{\tt ind-hyp}] E_i - (E_i {\tt div}E_{i+1})E_{i+1} = E_{i+2}$.

So if $E_i$ is the last term of the sequence, we have ${\tt gcd}(a,b)=E_i = aX_i +bY_i$.


\end{description}
We will spend time in class examining these formal proofs (I didn't give proofs in the first lecture, just built tables, but in fact I am saying basically the same thing).

I set up the main in-class example:  compute ${\tt gcd}(1024,137)$ (other knowledge tells us this will be 1) and find $x,y$ so that
1024$x$ + 137$y$ = ${\tt gcd}(1034,137)$, which we will find is 1.

$$\begin{array}{c|c|c|c}

&x & y& q \\

1024 & 1&0 &\\

 137 & 0 & 1 &\\

 65 & 1 & -7 & 7\\

7 &-2 & 15& 2 \\

 2 &19 & -142& 9 \\

 1 &-59 & 441 & 3
\end{array}$$

The first column is the sequence $E$, the second the sequence $X$, the third the sequence $Y$.  The fourth column contains the quotients used.

The final result is that ${\tt gcd}(1024,137)= 1 = (-59)(1024)+(441)(137)$.

I provide a spreadsheet you can use to do these calculations, but you do need to know how to do them by hand with the assistance of a calculator.

\section{Thursday, January 21, 2022}

My apologies to the class for the initial disruption.  I'm working with my technically minded son on getting a scheme for delivering Zoom sessions that will be useful to students out of class:  and yes, he got the web cam software to work in a flash.

I talked through some topics in Crisman related to the Tuesday lecture.

I spent some time discussing the more formal way I presented the extended Euclidean algorithm in the notes:  I said the same thing in the Tuesday lecture, but I did not define the sequences used in the formal presentation.

\begin{description}

\item[Theorem:]  If ${\tt gcd}(a,b)$ is defined, then ${\tt gcd}(a,b)$ is the smallest positive integer which can be written in the form $ax+by$ where $x$ and $y$ are integers (i.e, as an integer linear combination of $a$ and $b$.)

\item[Proof:]  By the extended Euclidean algorithm theorem, ${\tt gcd}(a,b)$ can be written in this form.

Now suppose that $w=ax+by$ for integers $x$ and $y$, and $w$ is positive.  ${\tt gcd}(a,b)|a$ and ${\tt gcd}(a,b)|b$, so ${\tt gcd}(a,b)|ax$ and ${\tt gcd}(a,b)|by$ so ${\tt gcd}(a,b)|ax+by=w$.  A positive multiple of any integer $z$ must be $\geq z$ (can you prove this?) so ${\tt gcd}(a,b)\leq w$, so ${\tt gcd}(a,b)$ is the smallest positive number which can be expressed in the form $ax+by$.

\item[Definition:]  The theorem that ${\tt gcd}(a,b)=ax+by$ for some integers $x,y$ is called the Bezout identity.  I learned this preparing for this class!

\item[Observation:]  The $x,y$ in the Bezout identity are not unique (though there is a specific one we find with the extended Euclidean algorithm (EEA)).  Suppose I want $ax+by = a(x+u) + b(y-v)$.  For this to be true, it is sufficient for $au=bv$ to hold.  $u=b$ and $v-a$ will work, giving
$a(x+b) + b(y-a)$ with the same value as $ax+by$.  For this to work, it is sufficient for $au=bv$ to be a common multiple of $a$ and $b$ and this may be less than the product $ab$:  $b$ is not necessarily the smallest number that can be added to $x$ here, nor $a$ the smallest number that can be subtracted from $y$.

\item[Definition:]  We say that $a$ and $b$ are {\em relatively prime\/} iff ${\tt gcd}(a,b)=1$.  This is a familiar concept, but it probably wasn't defined in this exact way when you first encountered it.

\item[Theorem (Euclid's lemma):]  If $p$ is a prime and $p|ab$ then either $p|a$ or $p|b$.

Study this proof.  You might be asked to write it.

Either $p|a$, in which case we are done, or $p\not|a$.  

So the rest of the argument is in the case $p\not|a$:  we need to show that in this case $p|b$.

Because $p$ is prime, ${\tt gcd}(p,a)=1$, so there are integers $x,y$ such that $px+ay=1$.

So $b=1b=(px+ay)b = pxb + ayb$.  $pxb$ is obviously divisible by $p$,  $ayb$ is divisible by $p$ because $ab$ is divisible by $p$.
Thus $b=pxb +ayb$ is divisible by $p$, which is what we needed to show.

\item[Prop 2.4.9 part 1:]  Suppose ${\tt gcd}(ab) = 1$.  If $a|c$ and $b|c$ then $ab|c$ (this theorem shows that in this case $ab$ is the least common multiple of $a$ and $b$).

\item[Proof:]  Suppose ${\tt gcd}(ab) = 1$.  Suppose $a|c$ and $b|c$.  Our goal is to show $ab|c$.

Since $a|c$ we have $x$ such that $ax=c$.  Since $b|c$ we have $y$ such that $by=c$.  Since ${\tt gcd}(ab) = 1$ we have $u$ and $v$ such that $au+bv=1$.  Now $c=1c=(au+bv)c=auc + bvc= auby + bvax = ab(uy+vx)$ which is divisible by $ab$ by inspection, so $ab|c$, which is what we needed to prove.

\item[Prop. 2.4.9 part 2:]  Suppose ${\tt gcd}(ab) = 1$.  Suppose $a|bc$.  Then $a|c$.

Since $a|bc$ we have $bc=xa$ for some $x$.  Since ${\tt gcd}(ab) = 1$ we have $ay+bz=1$ for some $y,z$.  Thus $c=1c = (ay+bz)c=ayc+bzc=ayc +bxa=a(cy+bx)$ which is divisible by $a$ by inspection, so $a|c$, which is what we need to show.

\end{description}

I was setting out to prove Prop 3.7.1 at the end of class.  These notes may contain a proof of that theorem before Tuesday's class:  keep an eye on them.

\newpage

\section{Homework 2, assigned 1/21/2022, due 1/27/2022}

In section 2.5 in Crisman, problems 3, 5 (you may use my spreadsheet, but say how you did it), 6, 7, 8 (with no more than a simple calculator;  of course I cannot stop you from using the spreadsheet to check, but you do need to know how to do this by hand for in-class tests), 10 (same remark as on 8), 15 (coprime is another word for ``relatively prime"), 17, 20.

\section{A Problem Solved:  Pythagorean Triples}

\begin{description}

\item[Definition:]   A {\em Pythagorean triple\/} is a triple of natural numbers $a,b,c$ such that $a^2+b^2=c^2$.

\item[Geometric Motivation:]   For any Pythagorean triple $a,b,c$ , there is a right triangle with legs $a,b$  and hypotenuse $c$.  The 3,4,5 Pythagorean triple can be used as a practical method to form a right angle.

\item[Example:]  $3^2+4^2=5^2$

\item[Definition:]  A {\em primitive Pythagorean triple\/} is a Pythagorean triple with no common factors other than 1.

\item[Motivation:]  If $a,b,c$ are a Pythagorean triple and $d \neq 1$ is a common factor of $a,b,c$,
so $a'd=a, b'd=b, c'd=c$, then $(a'd)^2 + (b'd)^2 = (c'd)^2$ implies $a'^2+b'^2=c'^2$ (divide both sides by
$d^2$).   If we further let $d$ be the greatest common divisor of $a,b,c$, then $a',b',c'$ will be a primitive Pythagorean triple.   So if we know all the primitive triples, we can obtain all the triples by multiplying by constants.

\item[Lemma:]  In a primitive Pythagorean triple $a,b,c$, the numbers $a,b$ will neither both be odd nor both be even.

\item[Proof:]  if $a,b$ were both even, then $a^2+b^2+c^2$ would be even, so $c$ would be even and
$a,b,c$ would not be a primitive triple.

If $a,b$ were both odd, then $a=2x+1$, $b=2y+1$, and since $a^2+b^2=c^2$ would be even, $c^2$ and so $c$
are even, so we can set $c=2z$.   Now $a^2+b^2=(2x+1)^2+(2y+1)^2 = 4x^2+4x+4y^2+4y+2$ is not divisible by 4, while $(2z)^2= 4z^2$ is divisible by 4.  But these two quantities are supposed to be equal.  So this situation is impossible.

\item[Observations:]  Let $a,b,c$ be a primitive Pythagorean triple.   We may safely assume that $a$ is odd and $b$ is even (if not we could switch them), and $c$ is thus odd.

Since $a^2+b^2=c^2$ we have $a^2=c^2-b^2=(c+b)(c-b)$.

$c+b$ and $c-b$ have no common factors.  Both are odd numbers.   If $d$ were a prime factor of both,
$d$ would be odd and $d$ would also be a factor of $2c$ (their sum) and $2b$ (their difference) and so would be
a factor of both $c$ and $b$ which is impossible as we have a primitive triple.

$a^2$ is a perfect square, so every prime in its factorization has an even exponent.  Any prime which goes
into $a^2$ goes into only one of $c+b$ and $c-b$, and in fact we can see that the exponent of each such prime must be the same as its exponent in the expansion of $a$, and so even.  And so $c+b$ and $c-b$ are perfect squares.

Set $c+b = s^2$ and $c-b=t^2$.   Notice that $s$ and $t$ have no common prime factors, as any common prime factor of these would be a common factor of $b$ and $c$ by reasoning already given.

Algebra gives $c=\frac{s^2+t^2}2$ and $b=\frac{s^2-t^2}2$.  $a^2=(c+b)(c-b)=s^2t^2$ so $a=st$.

\item[Theorem:]   Every primitive Pythagorean triple is of the form $st$, $\frac{s^2-t^2}2$, $\frac{s^2+t^2}2$,
where ${\tt gcd}(s,t)=1$ and $s,t$ are both odd..   Moreover, all such triples are primitive Pythagorean triples.

\item[Proof:]   The first sentence has been shown to be true in the observations above.  The second sentence
requires slightly more work.

That for any $s,t$ at all  ($s>t$, both odd or both even) $st$, $\frac{s^2-t^2}2$, $\frac{s^2+t^2}2$ is a Pythagorean triple is just algebra.

What remains is to shown that if ${\tt gcd}(s,t)=1$, then this triple is primitive.   It is enough to show
that $\frac{s^2-t^2}2$, $\frac{s^2+t^2}2$ have no common factors.   Any prime common factor of these two
numbers would be a prime factor of $s^2$, the sum of these two numbers, and $t^2$, their absolute difference.
But any prime which goes into $s^2$ and $t^2$ also goes into $s,t$ (by the lemma on prime factorizations proved earlier), and $s,t$ have no common prime factor.

\end{description}

To my mind, this is an example of the fact that proofs in number theory are often rather odd and indirect.  Others might not think so.

These notes are taken from a context where the usual results about prime factorizations were assumed.  We will justify our appeals
to prime factorizations using two specific facts, Prop 3.7.1 and 7.7.2 from Crisman.  Notes on my proofs of these results will appear
here later.

\begin{description}

\item[Prop. 3.7.1:]  If $a^2 | b^2$ then $a|b$.  

\item[Proof:]  It isn't clear to me that my proof above uses this, but it is easy enough to prove.

We remark first that it is enough to prove this result when ${\tt gcd}(a,b)=1$:  assume the theorem in this special case, let $a,b$ be general integers, and assume $a^2 | b^2$.  Then if $d={\tt gcd}(a,b)$, we have $a=a'd$ and $b=b'd$ (because $d$ goes into $a,b$) and we have ${\tt gcd}(a',b')=1$, because if $a'$ and $b'$ had a nontrivial common factor $k$, $kd>d$ would go into both $a'd=a$, and $b'd=b$, and $d$ is the greatest common divisor of $a$ and $b$.  So we have $a'^2d^2 | b'^2d^2$, from which we have $a'^2|b'^2$, from which we have $a'|b'$ by the special case of the Theorem, from which we have $a'd=a|b = b'd$.

Now we prove the special case.  Suppose that $a^2|b^2$ and ${\tt gcd}(a,b)=1$.  Then for suitable $x,y$ we have $ax+by=1$ so we have
$b = b1 = b(ax+by) = abx + b^2y$.  $a$ goes into $abx$ by inspection and it goes into $a^2$ which goes into $b^2y$ by hypothesis.

\item[Prop. 3.7.2:]  For any integers $a,b,c$, if ${\tt gcd}(a,b)=1$ and $ab=c^2$ then $a$ and $b$ are perfect squares.

\item[Proof:]  We expect, in fact that $a = {\bf gcd}(a,c)^2$.

Certainly ${\bf gcd}(a,c)^2 | c^2$.  Equally clearly, ${\bf gcd}(a,c)^2$ is relatively prime to $b$, so it goes into $a$ by theorems already shown, since $ab=c^2$ and $a,b$ have no common factors.  Thus ${\bf gcd}(a,c)^2 | a$.

Now show that $a|{\tt gcd}(a,c)=(ax+cy)^2$ for suitable $x,y$, $= a^2x^2 + 2acy +c^2y$, and $a$ goes into the first two terms by inspection and the last because $c^2=ab$.  So $a|{\bf gcd}(a,c)^2$.

Two positive integers which go into each other are equal.

I am proud of this proof, it is much better than the one in Crisman!

\end{description}

\section{Everything you might want to know about primes$\ldots$well, on day one:  lecture of 1/27/2022}

We discuss the important notions of prime and composite number.

\begin{description}

\item[Definition:]  A prime number is a positive integer with exactly two positive integer divisors.

\item[Observations:]  Every positive integer $n$ has 1 and $n$ as divisors.  If $n=1$, this fails to meet our definition, so 1
is not prime.  If $n>1$, then $n$ has at least two positive integer divisors, and will be prime just in case it has no others.
So the definition given is equivalent to ``$n$ is prime iff $n>1$ and has no factors other than 1 and itself."

\item[Definition:]  A positive integer $n$ is composite iff there are integer $a,b$ with $1<a \leq b < n$ and $ab=n$.
Notice that 1 is not composite.

\item[Theorem:]  Every natural number $n \geq 2$ can be expressed as a prime or a finite product of primes.

\item[Proof:]  Use the Well-Ordering Principle, and argue by contradiction.

If there is an integer $w \geq 2$ which is neither a prime nor a finite product of primes, then there is a smallest one, because the set of such integers would be a nonempty set of positive integers, and so have a smallest element.

Suppose that the Theorem is false, so this $w$ exists.

$w$ is not 1 and is not prime, so there are $a,b$ with $1<a\leq b <w$ and $w=ab$.

Since $a<w$ $b<w$ and $a$ and $b$ are both $\geq 2$ they are each either primes or finite products of primes.
But then $ab=w$ is a finite product of primes, which is a contradiction.

\item[Corollary:]  An immediate consequence is that any integer greater than one has at least one prime divisor.

\item[Theorem (Euclid?):]  There are infinitely many prime numbers.

\item[Proof:]  Suppose otherwise.  Then there is a finite list $p_1,\ldots,p_n$ containing all primes.  Define $P$ as
$\prod_{i=1}^n\,p_i$.  The integer $P+1$ is greater than 1, so it has a prime factor $q$.  There must be $j$ such that $q=p_j$.
Now $q|P$ because $P$ is the product of all primes, and $q|(P+1)$ by choice of $q$, so $q|(P+1)-P=1$, and $q|1$ is absurd.

\item[comments:]This proof is so well-known and (relatively) simple that some have proposed that every educated person should know it.

Here is a subtler related result.

\item[Theorem:]  There are infinitely many primes $p$ such that $p \,\,{\tt mod}\, \,4=3$.

\item[Comments:]  Obviously there are no primes $p$ such that $p \,\,{\tt mod}\, \,4=4$, and only one (2) such that $p \,\,{\tt mod}\, \,4=2$.
If $p$ is an odd prime, it will either be of the form $4k+1$ or the form $4k+3$.  It would seem natural that there are infinitely many primes of both kinds:  this is much easier to prove for 3 than for 1.

\item[Lemma:]  If $a \,{\tt mod}\, 4 =1$ and $b \,{\tt mod}\, 4 = 1$ then $ab \,{\tt mod}\, 4 = 1$.

$(4x+1)(4y+1) = 16xy + 4x+4y+1 = 4(4xy+x+y)+1$.  The Division Algorithm theorem tells us that the remainder is uniquely determined.

If $a \,{\tt mod}\, 4 =1$ and $b \,{\tt mod}\, 4 = 3$ then $ab \,{\tt mod}\, 4 = 3$.

$(4x+1)(4y+3) = 16xy + 12x +4y+3 = 4(4xy+3x+y)+3$.  The Division Algorithm theorem tells us that the remainder is uniquely determined.

If $a \,{\tt mod}\, 4 =3$ and $b \,{\tt mod}\, 4 = 3$ then $ab \,{\tt mod}\, 4 = 1$.

$(4x+3)(4y+3) = 16xy + 12x+12y +9 = 4(4xy +3x+3y+2)+1$.  The Division Algorithm theorem tells us that the remainder is uniquely determined.

\item[Corollary:]  Any integer of the form $4k+3$ must have a prime divisor of the form $4k+3$.

\item[Proof:]  Suppose otherwise.  Then the integer in question would have a prime factorization in which every prime was of the form $4y+1$, and a product of numbers of this form is of the form $4k+1$, not $4k+3$.

\item[Proof of the Main Theorem:]  Suppose that there are only finitely many primes $p_1,\ldots,p_n$ of the form $4k+3$.

Define $P$ as $\prod_{i=1}^n \, p_i$.

Either $P\,{\tt mod}\,4=1$ or $P{\tt mod 4}=3$.

In the first case $(P+2)\,{\tt mod}\,4 = 3$ so $P+2$ has a prime factor $q$ of the form $4x+3$, which goes into $P$ and $P+2$, so $q|2$, which is absurd, since $q$ is an odd prime.

In the second case, $(P+4)\,{\tt mod}\,4=3$ so $P+4$ has a prime factor $q$ of the form $4x+3$, which goes into $P$ and into $P+4$, and so goes into 4, which is absurd.

This can be proved, as a student noted, without cases.  Notice that $4P-1 = 4(P-1)+3$ is of the form $4k+3$, so has a prime factor $q$ of the form $4x+3$, and we observe that $q|4P$ and $q|(4P-1)$ so $q|1$, which is absurd.

\item[Theorem:]  Each positive integer can be expressed in exactly one way as the product of a nondecreasing sequence of primes.

\item[Proof:]  The statement in terms of a nondecreasing sequence is meant to tell us what is meant by uniqueness of factorization:  applications of the associative and commutative laws of multiplication do not give different factorizations.

We prove this by contradiction using the Well-Ordering Principle.

Suppose there is some $w = \prod_{i=1}^n p_i = \prod_{i=1}^m q_i$ where $p$ and $q$ are different finite nondecreasing sequences of primes.
Then there is a smallest such $w$ by the W.O.P.

We argue that $p_1$ cannot be one of the $q_i$'s, say $q_j$.  If it were, then $\frac w{p_1} = \prod_{i=2}^n p_i = \prod_{i=1 \wedge i\neq j}^m q_i$  would be both less than $w$ and would have two different prime factorizations, which is a contradiction.  (Removing the same term from two nondecreasing sequences of integers which are distinct must give distinct sequences; otherwise, adding the same term back, necessarily in the same position because the order determines it, would give the same sequence).

Now we prove using Euclid's Lemma and induction, that $p_1 | \prod_{i=k}^m q_i$ for all $k$ for which this makes sense.

Basis:  $p_1 | \prod_{i=1}^m q_i = w$.

Induction step:  Suppose $p_1 | \prod_{i=k}^m q_i$.  $\prod_{i=k}^m q_i= (q_k)^z\prod_{i=k+z}^m q_i$ for some $z$ with $q_{k+z}\neq q_k$ (I overlooked this in class, but so did everyone else) [or $\prod_{i=k}^m q_i= (q_k)^z$, in which case we have immediately that $p_1\neq q_k$ does not go into it, contradicting the inductive hypothesis].  These two numbers,  $(q_k)^z, \prod_{i=k+z}^m q_i$ are relatively prime, and $p_1$ goes into their product, so by Euclid's Lemma $p_1$ goes into one of the factors.  But it does not go into $(q_k)^z$, so it must go into $\prod_{i=k+z}^m q_i$,
and so it goes into $\prod_{i=k+1}^m q_i$, which can differ only in having more factors.

This completes the embedded induction proof.

So set $k=m$ and we have $p_1 | \prod_{i=m}^m q_i = q_m$, which is absurd. And this completes the proof.


\newpage

\end{description}


\section{Homework 3, posted 1/28/2022, due one week from 1/27/2022}

Homework 3: Use the results proved in class to describe at least five distinct primitive Pythagorean triples; do problems 14, 18, 19 on p. 34 in Crisman; as an extension of problem 19 look for patterns as to which numbers in a PPT can be divisible by 5 (for this, at least display some results of investigation; I'll be impressed if you can prove something). On p. 75 do problems 2,5,10,12,13. I like problem 20 on the next page; I'm not requiring it but Ill award EC if you do it.

\newpage

\section{Modular arithmetic lectured, Feb 1 and 3}

We begin by defining the congruence relation.

\begin{description}

\item[Definition (congruence mod m):]  Let $m>1$ and let $x,y$ be integers.  We say $x \equiv y \,\,{\tt mod}\, \, m$, or compactly
$x \equiv_m y$, just in case $m|(x-y)$.

\item[Theorem:]  $x \equiv y \,\,{\tt mod}\, \, m$ if and only if $x \,{\tt mod}\, m = y \,{\tt mod}\, m$.

\item[Proof:]  I suggest that you try to write the proof.  It follows from the Division Algorithm theorem.  You have to show the implication in both directions.

\item[Theorem:]  $\equiv_m$ is an equivalence relation.

\item[Proof:]  We need to prove that this relation is reflexive, symmetric, and transitive.

Let $m>0$.  Let $x,y,z$ be arbitrarily chosen integers.

We want to show $x \equiv_m x$.  This means $m|(x-x)$ which is equivalent to $m|0$, which is true.

We want to show that if $x \equiv_m y$ then $y \equiv_m x$.  Assume that $x \equiv_m y$.  This means $m|(x-y)$ and thus
for some integer $k$, $x-y=km$.  But then $y-x=(-k)m$, so $m|(y-x)$, so $y \equiv_m x$. 

We want to show that if $x \equiv_m y$  and $y \equiv_m z$, $x \equiv_m z$ follows.  Suppose $x \equiv_m y$  and $y \equiv_m z$.
Then $m|(x-y)$ and $m|(y-z)$.  It follows that $m|((x-y)+(y-z))$ and $(x-y)+(y-z)=x-z$ so $m|(x-z)$ so $x \equiv_m z$.

The proof is complete.

\item[Theorem:]  $\equiv_m$ respects addition and multiplication in the sense that if \newline $x\equiv_m x'$ and $y\equiv_m y'$ we have
$x+y \equiv_m x'+y'$ and $x\cdot y \equiv_m x' \cdot y'$.

\item[Proof:]  Suppose $x\equiv_m x'$ and $y\equiv_m y'$.  This is equivalent to there being integers $u$ and $v$ such that $x'=x+um$ and $y' = y+vm$.

Then $x'+y' = (x+um)+(y+vm) = (x+y) + m(u+v)$, so $x+y \equiv_m x'+y'$.

and $x'\cdot y' = (x+um)(y+vm) = x\cdot y + m(xv + yu + uvm)$, so $x\cdot y \equiv_m x' \cdot y'$.

This allows us to make addition and multiplication tables for mod $m$ arithmetic, with just the finite system of ``numbers" from 0 to $m-1$.

The interpretation of these ``numbers" admits two possibilities:  we can interpret them as congruence classes of integers, that is,
equivalence classes under $\equiv_m$, or as the remainders on division by $m$.  Either approach works.  The numbers may be called residues, if we think of them as remainders, or residue classes, if we think of them as equivalence classes.

For mod 4 arithmetic, we have

$$\begin{array}{c|cccc}

+ & 0& 1 &2& 3 \\ \hline

0 & 0& 1 &2& 3 \\
1 & 1& 2 &3& 0 \\
2& 2& 3 &0 & 1 \\
3& 3& 0 &1 & 2 \\

\end{array}$$

as the addition table.  Notice that each number has an additive inverse.  This is not surprising as the original system of integers on which this is based has additive inverses.  In general, the addition inverse of $a$ mod $m$ is $m-a$. For example the additive inverse of 3 mod 10 is 7.

For mod 4 arithmetic, we have 

$$\begin{array}{c|ccccc}

* & 0& 1 &2& 3 \\ \hline

0 & 0& 0 &0& 0 \\
1 & 0& 1 &2& 3 \\
2& 0& 2 &0 & 2 \\
3& 0& 3 &2 & 1 \\

\end{array}$$

Notice that the facts about multiplication of numbers of the forms $4k+1$ and $4k+3$ which we used in theorems proved earlier are encoded in this table.

Notice that we do not have multiplicative inverses for all nonzero numbers in this system:  we have $x$ such that $3x=1$ and $x$ such that $1x=1$
but no $x$ such that $2x=1$.  We do not have multiplicative inverses in the integers, so this is not surprising.

If we look at the multiplication table for mod 5 arithmetic, something unexpected happens.

$$\begin{array}{c|ccccc}

* & 0& 1 &2& 3 & 4\\ \hline

0 & 0& 0 &0& 0 &0 \\
1 & 0& 1 &2& 3 & 4\\
2& 0& 2 &4 & 1 & 3 \\
3& 0& 3 &1 & 4 & 2\\

4 & 0 & 4 & 3 & 2 & 1

\end{array}$$



\end{description}

Each nonzero residue has a multiplicative inverse:  the recprocal of 1 is 1, of 2 is 3, of 3 is 2, of 4 is 4.

This is surprising:  the system ends up looking more like the rationals than like the integers.

There is a theorem of course

\begin{description}

\item[Theorem:]  For each residue $a$ in mod $m$ arithmetic, there is an $x$ such that $ax \equiv_m 1$ if and only if
${\tt gcd}(a,m)=1$.

\item[Proof:]  If $ax \equiv_m 1$ then $ax-1$ is divisible by $m$, so any common divisor of $ax$ and $m$ would also be a divisor of 1,
so certainly $a$ and $m$ have no nontrivial common factors.

If ${\tt gcd}(a,m)=1$ then there are integers $x$ and $y$ such that $ax+my=1$, so for this $x$, $ax \equiv_m 1$.

\end{description}

This doesnt quite say that if ${\tt gcd}(a,m)=1$ implies that $a$ has a multiplicative inverse mod m.  The proof of this is completed
by the following observation:

\begin{description}

\item[Theorem:]  For each residue $a$ in mod $m$ arithmetic, if ${\tt gcd}(a,m)=1$ and $ax \equiv_m ay$ (and so in particular if $ax=ay=1$, which implies ${\tt gcd}(a.m)=1$) then $x \equiv_m y$.

\item[Proof:]  If ${\tt gcd}(a,m)=1$ and $ax \equiv_m ay$, then $m|a(x-y)$, and then by theorems proved above, $m|(x-y)$, since $m$ is relatively prime to $a$, and so $x \equiv_m y$.

\end{description}

This has the incidental effect that the multiplicative inverse of $a$ in mod m arithmetic, if it exists, is unique (up to congruence mod m).  More generally, it is a version of the cancellation property of multiplication.

\begin{description}

\item[Definition:]  We say that $a^{-1} \,\,{\tt mod}\, \,m$ is the unique remainder mod m such that $ax \equiv_m 1$, if it exists.

\item[Observation:]  If $p$ is prime, $a^{-1}\,\,{\tt mod}\,\,p$ is defined for each $a$ such that $a \not\equiv_p 0$.  That is, modular arithmetic mod $p$ satisfies the multiplicative inverse property.

\item[Proof:]  We have shown above that $a^{-1}\,\,{\tt mod}\,\,m$ is defined iff $a$ and $m$ are relatively prime.  A prime $p$ is relatively prime to any $a$ unless $p|a$, that is, $a \equiv_p 0$.

\end{description}

And this is surprising.  This means in effect that division is defined in the mod p integers, whereas it is not defined in the integers as usually understood.

In general, it should be easy to convince yourself that for any m, mod m arithmetic inherits from the integers the commutative, associative and distributive laws, the identity laws. and additive inverses.  It does not inherit the zero factor property:  you might want to work out
why the fact ``if $ab=0$ then $a=0$ or $b=0$" which is true in the integers does not carry over to mod m arithmetic unless m is prime.
And the fact that the multiplicative inverse property characteristic of the rationals holds in mod p arithmetic is a surprise.

What mod m arithmetic does not have which distinguishes it from the arithmetic of the integers is order properties.

\begin{description}

\item[Example:]  Compute $12^{-1} \,{\tt mod}\, 137$.

Use the usual Euclidean algorithm calculation (my table) to find $x$ and $y$ so that $137x + 12y = 1$, so $12y \equiv_{137} 1$.

We get $(137)(5) + 12(-57) =1$, so $y$ is to be $-57$...but the additive inverse of 57 in mod 137 arithmetic is 137-57 = 80, the answer.
You will need to make this last move about half the time.

It is wise to check that (80)(12) \,{\tt mod}\, 137 is indeed 1.

\end{description}

\subsection{Exponentiation}

It is not the case that exponentiation respects congruence mod m.  That is, it is not true in general that if $x \equiv_m y$ and
$r \equiv_m s$ that $x^r \equiv_m y^s$.  It {\em is} true that if $x \equiv_m y$ then $x^r \equiv_m y^r$ :  this is true by repeated application of the fact that congruence respects multiplication.

Nonetheless, the pattern continues that we can efficiently compute congruence facts about large numbers by ignoring everything about them but their remainder mod m.

\begin{description}

\item[Algorithm (modular exponentiation):]  To compute $x^r\,\,{\tt mod}\, m$, first compute $x^{r {\tt div} 2}\,\,{\tt mod}\,\,m$.  Then
if $r \,{\tt mod}\,2=0$, $x^r\,\,{\tt mod}\, m = (x^{r {\tt div} 2})^2\,\,{\tt mod}\,\,m$ and if $r \,{\tt mod}\,2=1$, $x^r\,\,{\tt mod}\, m = ((x^{r {\tt div} 2})^2\cdot x)\,\,{\tt mod}\,\,m$, in either case a small multiplication problem mod m.

This is a recursive computation:  at the basis, note that we can certainly compute $x^1 \,\,{\tt mod}\,\, m$.

\end{description}

In practice, I execute the algorithm by making a list of exponents obtained by starting with $r$ and successively dividing by 2, throwing away remainders, then computing the powers from 1 upward.

\begin{description}

\item[Example:]  Compute $32^{1153}\,\,{\tt mod}\, 100$.  100 is a convenient modulus just because it is easy to take remainders on division by 100.

$$\begin{array}{c | c}

1153 & 76^2\cdot 32 = 184832 \equiv 32\\

576 & 76^2 = 5776 \equiv 76\\

288 & 76^2 = 5776 \equiv 76\\

144 &  76^2 = 5776 \equiv 76\\

72 & 76^2 = 5776 \equiv 76\\

36 &  24^2  =576 \equiv 76\\

18 & 32^2 = 1024 \equiv 24\\

9 &  76^2\cdot 32 = 184832 \equiv 32\\

4 & 24^2 = 576 \equiv 76\\

2 &  32^2 = 1024 \equiv 24\\

1 &  32\\

\end{array}$$

\end{description}

This turned out to be a rather special example, but the pattern should be clear enough.  This is known as the method of repeated squaring (with addition of an extra copy of the base at odd exponents).  The number of multiplications is roughly proportional to the log base 2 of the exponent, so this will handle very large exponents with computer support (hundreds of digits are no challenge).

I'll add more notes here about Fermat's Little Theorem, $a^{p-1} \equiv_p 1$ for $p$ prime, and the way it allows much simpler computation of exponentials.  I do not think it figures in your homework.


\subsection{The Linear Congruence Theorem}

In this section we look at the precise conditions under which a linear congruence
$$ax \equiv b \,\,{\tt mod}\,\, m$$ has a solution and how many solutions it has.

First of all, we can apply the results about multiplicative inverses in moduli to solve a special case.

\begin{description}

\item[Theorem:]  If ${\tt gcd}(a,m)=1$ then $$ax \equiv b \,\,{\tt mod}\,\, m$$ has exactly one solution $x$.

\item[Proof:]   ${\tt gcd}(a,m)=1$ then $a^{-1}\,\,{\tt mod}\,\,m$ exists, which we will just write $a^{-1}$.

$ax\equiv_mb$ implies $a^{-1}ax\equiv_ma^{-1}b$ which implies $x\equiv_ma^{-1}b$.  And further, $a(a^{-1}b) \equiv_m b$ is true.  So there is exactly one solution for $x$, that is
$(a^{-1}\, \,{\tt mod}\,\, m)\cdot b$.

\end{description}

We now consider the general situation.

\begin{description}

\item[Convention:]  In everything that follows until the main theorem is proved, let $d={\tt gcd}(a,m)$.

\item[Lemma:]  If $d \not|b$, then there is no solution $x$ for $ax \equiv b \,\,{\tt mod}\,\, m$.

\item[Proof:]  If $ax \equiv_m b$ then $b = ax+km$ for some integer $k$ and so since $d|a$ and $d|m$ we have $d|b$.  We have proved $ax \equiv_m b \rightarrow d|b$, from which the contrapositive $d\not|b \rightarrow ax \not\equiv_m b$ follows.

\item[Lemma:]  If $d|b$ then there is at least one solution to $ax \equiv b \,\,{\tt mod}\,\, m$. 

\item[Proof:]  If $d|b$ then all of $\frac ad, \frac md, and \frac bd$ are integers, and ${\tt gcd}(\frac ad,\frac md)=1$, so there is a unique solution $x$ to
$\frac adx \equiv \frac bd \,\,{\tt mod}\,\, \frac md$.  For this $x$, we have $\frac adx + k\frac md = \frac bd$ for some integer $k$, so we have
$ax+km=b$, so $ax \equiv_m b$.

\item[Main Theorem:]  Let $m>0$.  Let $a,b$ be integers.  Let $d={\tt gcd}(a,b)$.  If $d \not|b$ then $ax \equiv_m b$ has no solutions.
Otherwise this equation has $d$ solutions.

\item[Proof:]  Let $x$ be the unique solution to $\frac adx \equiv \frac bd \,\,{\tt mod}\,\, \frac md$.  We know that $ax \equiv_m b$.
Suppose $ay \equiv_m b$.  It follows that for some $k$, $ay + km = b$.  Thus $\frac ady + k\frac md = \frac bd$ so $\frac ady + k\frac md = \frac bd$,
so $\frac ad y \equiv_m \frac bd - k\frac md$.  This calculation is reversible:  a solution of this equation for any $k$ is a solution of the original equation.
For each $k$, this equation has exactly one solution, because $\frac ad$ is relatively prime to $m$.  And $k\frac md \equiv_m k'\frac md$ just in case
$k \equiv k' \,\,{\tt mod}\,\, d$, so there are in effect $d$ possible values for $k$, and so $d$ solutions to the original equation up to congruence.

\end{description}

I was having difficulty with details of this last proof under the influence of muscle relaxant on Thursday;  I will be lecturing it and giving numerical examples for computation on Tuesday.



\newpage


\section{Abstract algebra definitions lectured, Feb 3}

I have nothing particular of my own to say about these definitions yet.  I may soon revisit this and write more notes.

The definition of group on pp. 33-4 was lectured, and some theorems on p 36 (Props 3.17-18, uniqueness of the identity and the inverse).  Examples given after the definition may be instructive.

The definition of ring on p. 191 was lectured.  The definitions of extensions of this notion listed at the bottom are important.  Notice that
the integers are a ring but not a field (because not a division ring) and the integers are an integral domain (because they do satisfy the zero factor theorem).
Notice that mod p arithmetic gives a field, surprisingly, but that mod m arithmetic where m is composite gives a commutative ring which is not an integral domain (the zero factor theorem fails).

I will be happy to take questions about the questions from Judson which I ask, which are occasions for mathematical exploration.

I also may well settle down later and expand this section.  I'm tired out from all the stuff I wrote about modular arithmetic!

\section{Homework 4, due Feb 10}

Homework 4:  p.47 Crisman, 2, 3, 7, 12, 18, 19, p. 62 6, 10, 11, 13 (you can ask for others from 8-13), Judson, p. 40 problem 2, Judson, p. 205 problem 1 (do at least four parts)

\section{Notes on the Linear Congruence Theorem and the Chinese Remainder Theorem, Feb 8 and Feb 10 2022}

\subsection{What are the numbers of modular arithmetic?}

First, I am going to chat a little about what the objects are in mod m arithmetic.

Mod $m$ arithmetic is a finite system, with objects we usually refer to as $0,1,\ldots,m-1$.  There is some creative ambiguity in what these objects actually are.

They could be viewed as the remainders on division by $m$ (which are also called residues mod $m$).  In this case, when we compute
$p+q$ in mod $m$ arithmetic, we are computing $(p+q) \,{\tt mod}\, m$ in the ordinary sense, in order to be sure our answer is a remainder, and similarly for subtraction, additive inverse and multiplication (but {\bf not} for multiplicative inverse or division).

They could be viewed as equivalence classes of integers under the relation of congruence mod $m$.  In this case, we would understand $p$ and $q$ in mod $m$ arithmetic as shorthand for $\{p+km:k \in {\mathbb Z}\}$  and $\{q+km:k \in {\mathbb Z}\}$ (where $p$ and $q$ are the integers of the  same name)
and when we compute $p+q$ in mod $m$ arithmetic, we are adding elements of the sets:  $\{(p+km) + (q+k'm):k, k' \in {\mathbb Z}\}$ is exactly the same set
as $\{((p+q) \,{\tt mod}\,m)+km:k \in {\mathbb Z}\}$ (writing this out shows me what a complicated idea it is that I am asking you to accept!)

In general, which approach we are using does not make any difference.  When we say that an integer $x$ is to be ``identified" with $p$ in the sense of modular arithmetic
we can be taken as saying either that $x \,{\tt mod}\,m = p$ (if $p$ is understood as a remainder on division by $m$) or that $x \in p$ if $p$ is understood as the equivalence class $\{p+km:k \in {\mathbb Z}\}$ where $p$ is the integer of the same name).  The operations of modular arithmetic behave in the same way under either understanding.
\newpage
\subsection{The Linear Congruence Theorem, again}

I recapped the proof of this via a series of lemmas.  Some of these lemmas are theorems in their own right.

\begin{description}

\item[Lemma 1:]  Let $m>0$.  Let $a$ be a residue mod $m$ (recall that this just means, a remainder mod $m$, so $0\leq a <m$).  Suppose that ${\tt gcd}(a,m)=1$.  Then there is a unique residue $b$ mod $m$ such that $ab \equiv_m 1$.

\item[Proof:]  Because ${\tt gcd}(a,m)=1$, there are integers $x,y$ such that $ax+my=1$.  Notice that $ax \equiv_m 1$ follows.  So $x\,{\tt mod}\,m =b$ gives a residue $b$ such that $ab \equiv_m 1$ as desired.

But we need to show that there is only one.  Suppose that $ax\equiv_m ay \equiv_m 1$, so $x\,{\tt mod}\,m$ and $y\,{\tt mod}\,m$ are both candidates to be the $b$ we are looking for.  Then $m|(ax-ay)$ so $m|a(x-y)$ so by Euclid's Lemma $m|(x-y)$ so $x \equiv_m y$ so $x \,{\tt mod}\,m = y\,{\tt mod}\, m$:  there is only one residue $b$ with the desired property.

\item[Definition:]  Let $m>0$.  Let $a$ be a residue mod $m$.  Define $a^{-1}\,{\tt mod}\,m$ as the unique residue $b$ such that $ab \equiv_m 1$. 

\item[Obervation:]  It isn't part of the theorem stated above, but it is worth observing that if ${\tt gcd}(a,m)=d>1$ then there can be no $b$ such that $ab \equiv_m 1$.
We would have $ax+my=1$ for some integers $x,y$ and then $ax+my=1$ divisible by $d$, which is absurd.  So $a^{-1}\,{\tt mod}\,m$ is defined if and only if $a$ and $m$ are relatively prime.

\item[Lemma 2:]  Let $m>0$.  Let $a$ be a residue mod $m$ which is relatively prime to $m$.  Let $b$ be a residue mod $m$.  Then there is exactly one residue $x$ mod $m$ such that $ax \equiv_m b$.

\item[Proof:]  Since $a$ is relatively prime to $m$, $a^{-1}\,{\tt mod}\,m$ exists;  we will write it just $a^{-1}$.  So $a(a^{-1}b) \equiv_m  (aa^{-1})b \equiv_m 1b \equiv_m b$,
so $x=a^{-1}b\,{\tt mod}\,m$ is a solution of $ax \equiv_m b$.

Now suppose that $x$ is any solution of $ax \equiv_m b$.  It follows that $a^{-1}(ax) \equiv_m a^{-1}b$, and $a^{-1}(ax) \equiv_m (a^{-1}a)x \equiv_m 1x \equiv_m x$,
so $x \equiv_m a^{-1}b$, and we see that $a^{-1}b\,{\tt mod}\,m$ is the only residue which can be a solution to the equation (there are many integers $x$ such that $x \equiv_m a^{-1}b$, but of these only $a^{-1}b\,{\tt mod}\,m$ is a remainder on division by $m$).

\item[Lemma 3:]  Let $m>0$.  Let $a$ and $b$ be residues mod $m$ and let $d = {\tt gcd}(a,m)$.  Then $ax \equiv_m b$ has a solution $x$ if and only if
$d|b$.

\item[Proof:]  Suppose $d|b$.  We have $a=a'd$ and $b=b'd$ and $m=m'd$ with ${\tt gcd}(a',m')=1$ (if $a'$ and $m'$ had a nontrivial common factor $e$, verify that $de>d$ would be a common factor of $a$ and $m$).  Thus by Lemma 2 there is a unique residue $x$ mod $m'$ such that $a'x\equiv_{m'} b'$.  For some integer $k$,
$a'x +km' = b'$ by this last congruence.  But then $a'dx + km'd = b'd$, that is, $ax+km = b$, so $ax \equiv_m b$.  So if $d|b$ there is a solution to the congruence.

Suppose there is a solution $x$ to $ax \equiv_m b$.  Then $ax+km = b$ for some integer $k$.  $d|ax$ because $d|a$, and $d|km$ because $d|m$, so $d|ax+km$, so $d|b$.

So we have shown that ${\tt gcd}(a,m)|b$ if and only if there is a solution to $ax \equiv_m b$.

\item[Linear Congruence Theorem:]  Let $m>0$.  Let $a$ and $b$ be residues mod $m$ and let $d = {\tt gcd}(a,m)$.  Then there are exactly $d = {\tt gcd}(a,b)$ solutions to $ax \equiv_m b\,{\tt mod}\, m$.

Let $a'd = a, b'd = b, m'd=m$, as in the previous problem.  Let $x$ be the unique solution to $a'x \equiv_{m'} b'$.

Any solution to $ax \equiv_m b$, say $y$,  has $a(x-y) = a'd(x-y)$ divisible by $m=m'd$, so $a'(x-y)$ divisible by $m'$.  This means that $x \equiv_{m'} y$.

Any $y$ of the form $x+m'k$ actually is a solution:  we have $ax+um = b$ for some $u$, so we have $b=a(x+m'k)-am'k+um = a(x+m'k)-a'mk+um [{\tt note}\, am'=a'm]\equiv_m a(x+m'k)$.

Any $y$ of the form $x+m'k$ has to be congruent mod $m$ to some $x+m'k$ with $0 \leq k < d$:  any larger or smaller number of the form $x+m'k$ we can convert to this form by adding or subtracting some multiple of $m'd = m$.  And no two of these numbers are congruent mod $m$, because any two of them differ by less than $m'd=m$.  So we have exactly $d$ solutions, the remainders $x+m'k\,{\tt mod}\,m$ for $k$ ranging from 0 to $d-1$.

Sample computations to appear here tomorrow morning.

\end{description}
\newpage
\subsection{The Chinese Remainder Theorem}

The Chinese Remainder Theorem allows us to solve simultaneous equations of the form $x \equiv_{m_1} a_1; x \equiv_{m_2} a_2;\ldots;x \equiv_{m_k}=a_k$ as long as for any $1 \leq i<j \leq k$ we have ${\tt gcd}(m_i,m_j)=1$.

We indicate how to solve this when there are two equations.

Suppose ${\tt gcd}(m,n)=1$.  We want to find an $x$ such that $x \equiv_m a$ and $x \equiv_n b$.  We show that we can find such an $x$, and moreover that
the solution is unique up to congruence mod $mn$.

We will mix things up a little and show the uniqueness first.  Suppose that $x \equiv_m a$ and $x\equiv_n b$ and $y \equiv_m a$ and $y\equiv_n b$ ($x$ and $y$ are both solutions to the system of equations).  Then $m|(x-y)$ and $n|(x-y)$.  But this implies, by a result already shown, that since $m,n$ are relatively prime, $mn|x-y$, so
$x \equiv_{mn}y$.  It should be clear that if $x \equiv_m a$ and $x \equiv_n a$ and $y \equiv_{mn} x$, then also $y \equiv_m a$ and $y \equiv_n b$.  So the solution set we are looking for, if it exists, will simply be a congruence class mod $mn$ (or a remainder mod $mn$ if we think of it in that style).

Now we argue that there is a solution.  Since $x \equiv_m a$, we have $x=a+km$ for some integer $k$.  Thus, if $x$ is a solution we must
have $a+km \equiv_n b$.  This gives us $km \equiv_n b-a$.  This gives us the solution $k = (b-a)(m^{-1} {\tt mod} n)$.

We plug this back into our equation for $x$ to get $x = a+(b-a)(m^{-1}{\tt mod}n)m$.  Clearly $x \equiv_m a$, because $(b-a)(m^{-1}{\tt mod}n)m$ is a multiple of $m$.
Further, $x \equiv_n b$ because $(m^{-1}{\tt mod}n)m \equiv_n 1$ so $x = a+(b-a)(m^{-1}{\tt mod}n)m \equiv_n a+(b-a)(1) = b$.

We actually compute solutions by using the extended Euclidean algorithm to compute multiplicative inverses.

Examples to appear here tomorrow morning.

\end{document}
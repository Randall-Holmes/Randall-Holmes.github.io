\documentclass[12pt]{article}

\title{Riemann integrals of continuous functions exist}

\author{Randall Holmes}

\usepackage{amssymb}

\begin{document}


\maketitle

In this snippet of notes, we will work toward proving that $\int_a^b f$ exists for any $f$ continuous on $[a,b]$ along with prerequisite and related results

We begin by proving that if a function $f$ is nondecreasing on $[a,b]$, $\int^a_b f$ exists.

Suppose that $f$ is nondecreasing on $[a,b]$.  (this means that for any $x,y \in [a,b]$ with $x<y$, $f(x) \leq f(y)$).

We will show that for any $\epsilon > 0$, there is a partition $P$ such that $U(f,P) - L(f,P)<\epsilon$.  It is a homework exercise in your current assignment that this is sufficient to
establish that $\int_a^b f$ exists.

Let $P$ be a partition $\{x_i\}_{0 \leq i \leq n}$ of $[a,b]$ such that there is a constant $\delta <\frac{\epsilon}{f(b)-f(a)}$ such that $x_i - x_{i-1} = \delta$ for each $i$ for which this is defined:  $P$ determines a subdivision
of $[a,b]$ into closed intervals all of the same length strictly less than $\epsilon$.

Now $$U(f,P) - L(f,P) = \sum_{i=1}^n (x_i-x_{i-1})(\sup_{[x_{i-1},x_i]}f -\inf_{[x_{i-1},x_i]}f)$$

$$= \sum_{i=1}^n \delta (f(x_i) -f(x_{i-1}))$$

[because the length of each interval in $P$ is $\delta$ and $\sup_{[x_{i-1}]}f = f(x_i)$ and $\inf_{[x_{i-1}]}f = f(x_{i-1})$ because
$f$ is nondecreasing ]

$$= \delta \sum_{i=1}^n (f(x_i) -f(x_{i-1})) = \delta(f(b)-f(a)) < \epsilon$$

[the second equation holds because $\sum_{i=1}^n (f(x_i) -f(x_{i-1}))$ is a telescoping sum]

And this completes the proof that $\int_a^b f$ exists, mod the homework assignment mentioned.

I strongly recommend and may assign proving the same result for nonincreasing functions $f$.

The proof that $\int_a^b f$ exists if $f$ is continuous on $[a,b]$ relies on the theorem that a function $f$ continuous on a closed
interval $[a,b]$ is uniformly continuous on $[a,b]$.  We first explain what this statement means, then use it to prove
that $\int_a^b f$ exists, then perhaps prove the prerequisite theorem.

That $f$ is continuous on a set $A$ means that for each $x \in A$, there is an $\epsilon>0$ such that for any $y \in A$,
if $|y-x|<\delta$ then $|f(y)-f(x)|<\epsilon$.  This follows from the usual definitions of limits and continuity which you should have known since undergraduate real anaysis if not since Calculus I.

That $f$ is uniformly continuous on a set $A$ means that for each $\epsilon >0$, there is $\delta>0$ such that for any $x,y \in A$,
if $|x-y|<\delta$ then $|f(x)-f(y)|<\epsilon$.

The second assertion is stronger:  it says that the tolerance of error $\delta$ you need such that if $y$ is that close to $x$,
$f(y)$ will be within $\epsilon$ of $f(x)$ does not depend on $x$:  the same tolerance works everywhere in the set $A$.

The prerequisite theorem is ``If $f$ is continuous on $[a,b]$, $f$ is uniformly continuous on $[a,b]$".  For the moment we assume
this and proceed to prove that $\int_a^b f$ exists.

Again, we will show that for any $\epsilon > 0$, there is a partition $P$ such that $U(f,P) - L(f,P)<\epsilon$.  It is a homework exercise in your current assignment that this is sufficient to
establish that $\int_a^b f$ exists.

Choose $\epsilon >0$ arbitrarily

Choose $\delta$ such that for any $x,y \in [a,b]$, if $|x-y|<\delta, |f(x)-f(y)|< \frac\epsilon{2(b-a)}$.

Let $P$ be the partition of $[a,b]$ determined by $\{x_i\}_{0 \leq i \leq n}$ subdividing the interval into closed intervals all with equal length $\delta$.

Now $$U(f,P) - L(f,P) = \sum_{i=1}^n (x_i-x_{i-1})(\sup_{[x_{i-1},x_i]}f -\inf_{[x_{i-1},x_i]}f)$$

$$= \sum_{i=1}^n \delta(\sup_{[x_{i-1},x_i]}f -\inf_{[x_{i-1},x_i]}f)$$

$$\leq \sum_{i=1}^n \delta \frac{\epsilon}{2(b-a)}$$

because $\sup_{[x_{i-1},x_i]}f -\inf_{[x_{i-1},x_i]}f \leq \frac{\epsilon}{2(b-a)}$ since the length of the interval is $\delta$
(any two points in the interval except $x_i$ and $x_{i-1}$ are at distance $<\delta$ and have values of $f$ differing by less than $\frac{\epsilon}{2(b-a)}$;  $x_i$ and $x_{i-1}$ are at distance exactly $\delta$ but continuity of $f$ lets us see that the values of $f$ at the endpoints might differ exactly by $\frac{\epsilon}{2(b-a)}$ but no more:  so the difference between the largest and smallest value
of the function on the interval is bounded above by $\frac{\epsilon}{2(b-a)}$ and $\sup_{[x_{i-1},x_i]}f -\inf_{[x_{i-1},x_i]}f$ is no greater than $\frac{\epsilon}{2(b-a)}$.

$$= \sum_{i=1}^n \frac{b-a}n \frac  {\epsilon}{2(b-a)} = \frac\epsilon2 < \epsilon$$

Note that $\delta=\frac{b-a}n$.

I'll lecture the proof that a continuous function on a closed interval is uniformly continuous on Sept 6;  notes on it will be added here eventually.

I lectured a series of results to get to the result on uniform continuity.  The quality of these notes may suffer from the fact that I am ill as I write;  please feel free to make any comments
or ask any questions that you think are needed.

\begin{description}

\item[Monotone convergence theorem:]  Fir any sequence $\{x_i\}$ which is either nondecreasing  ($i \leq j \rightarrow x_i \leq x_j$) and bounded above or nonincreasing ($i \leq j \rightarrow x_i \geq x_j$) and bounded below,
the limit $\lim_{i \rightarrow \infty} x_i$ exists.

This theorem should be familiar to you since the second calculus course, and you should have seen a proof in your first real analysis course, but I support varying levels of preparation:  I review it.

\item[Proof:]  We cover only the case of $\{x_i\}$ nondecreasing:  the proof in the other case is very similar.

Suppose that $\{x_i\}$ is a nondecreasing sequence and bounded above.  This means there is $b$ such that for every $i$, $x_i \leq b$.  This implies that the set $\{x_i:i \in \mathbb N\}$
is nonempty (it contains $x_1$) and bounded above by $b$.  This means that it has a least upper bound $L$.

We claim that $\lim_{x \rightarrow \infty}x_i = L$, that is, $(\forall \epsilon>0:(\exists N \in \mathbb N:(\forall i \in \mathbb N: i \geq N \rightarrow |x_i-L| <\epsilon)))$.

Choose $\epsilon>0$.  $L-\epsilon$ is not an upper bound of $\{x_i:i \in \mathbb N\}$, so there is $N$ such
that $x_N>L-\epsilon$.  Now for any $i > N$, we have $x_N \leq x_i$ (nonincreasing) so $L -\epsilon < x_N \leq x_i \leq L<L + \epsilon$, so
$|x_i -L|<\epsilon$, which is what we need.

\item[Bolzano-Weierstrass Theorem:]  For any $a < b$ real numbers, and any sequence $\{x_i\}$ of elements of $[a,b]$, there is a convergent subsequence of $\{x_i\}$, that is, there is a strictly increasing sequence
$\{s_i\}$ of natural numbers such that the sequence $y_i = x_{s_i}$ converges.

\item[Proof:]  We define sequences $\{A_i\}$ and $\{B_i\}$ recursively.

$A_0 = a$ and $B_0 = b$.

Suppose $A_i$ and $B_i$ have been defined, and there are infinitely many $j$ such that
$A_i \leq x_j \leq B_i$ [notice that this is true for $i=0$].

If there are infinitely many $j$ such that $A_i \leq \frac{A_i+B_i}2$, we define $A_{i+1}$ as $A_i$
and $B_{i+1}$ as $\frac{A_i+B_i}2$.

Otherwise, there will be infinitely many $j$ such that $\frac{A_i+B_i}2\leq B_i,$ and we define $A_{i+1}$ as
$\frac{A_i+B_i}2$ and $B_{i+1}$ as $B_i$.

Notice that we enforce the hypothesis of the recursion on both cases, so we will be able to define
$A_i$ and $B_i$ for each $i \in \mathbb N$.

More facts can be seen by induction on $i$:  $A_i \leq A_{i+1}$ and $B_i \geq B_{i+1}$ will always
hold, and $B_i - A_i = \frac{b-a}{2^i}$.

By the monotone convergence theorem, $\{A_i\}$ converges to a limit $L$ (nondecreasing and bounded above by $b$) and $\{B_i\}$ converges to a limit $M$ (nonincreasing and bounded below by $a$).  By the subtraction property of limits of sequences, $M - L = \lim_{i \rightarrow \infty} B_i - A_i =
\lim_{i \rightarrow \infty}\frac{b-a}{2^i}=0$, so $L=M$.

We define $s_0$ as 0 and define $s_{i+1}$ as the smallest $j>s_i$ such that $x_j \in [A_j,B_j]$:  infinitely many values of $j$ make the last statement true, so we can find one bigger than $s_i$.

The sequence $\{x_{s_i}\}_{i \in \mathbb N}$ is a subsequence of $\{x_i\}$ and it converges to $L$. because 
for any $i$, $A_{s_i} \leq x_{s_i} \leq B_{s_i}$, and as $i \rightarrow \infty$, $A_{s_i} \rightarrow L$
and $B_{s_i}\rightarrow L$, so $x_{s_i} \rightarrow L$ by the very familiar Squeeze Theorem.

\item[Definition:]  A function $f$ is continuous on a set $A$ iff $(\forall x \in A: \forall \epsilon >0:\exists \delta>0:\forall y \in A:|x-y|<\delta \rightarrow |f(x)-f(y)|<\epsilon)$.

A function $f$ is uniformly continuous on a set $A$ iff $(\forall \epsilon >0:\forall \delta >0: \forall x,y \in A:
|x - y|<\delta \rightarrow |f(x)-f(y)|<\epsilon)$.

Notice that uniform continuity is a stronger condition:  it allows you to select your $\delta$ given $\epsilon$ independently of where you are in the set $A$.

\item[Uniform Continuity Theorem:]  If $a<b$ are real numbers, and $f$ is continuous on $[a,b]$ then $f$ is uniformly continuous on $[a,b]$.

\item[Proof:]  Suppose that $a<b$ and $f$ is continuous on $a,b]$.

Suppose for the sake of a contradiction that $f$ is not uniformly continuous on $[a,b]$.

Then there is an $\epsilon>0$ such that for each $\delta$ we can choose $x,y \in [a,b]$ such that
$|x-y|\leq \delta$ but $|f(x)-f(y)| \geq \epsilon$.

In particular, for each $k \in \mathbb N$, we can choose $x_k,y_k \in [a,b]$ such that
$|x_k - y_k| < \frac 1k$ and $|f(x_k)-f(y_k)| \geq \epsilon$.

By the Bolzano Weierstrass Theorem, there is a sequence $U_k = x_{s_k}$ ($s$ strictly increasing)
which has a limit $L$.

Define $V_k$ as $y_{s_k}$.  By the Bolzano Weirstrass theorem there is a sequence $Y_k = V_{t_k}$ ($t$ strictly increasing) such that $Y_k$ has a limit $M$.  Define $X_k$ as $U_{t_k}$:  being a subsequence
of $U$, it has the same limit $L$ that $U$ has.

Now $L - M = \lim_{k \rightarrow \infty} (X_k - Y_k) = 0$, because $|X_k-Y_k| = |x_{s_{t_k}} - y_{s_{t_k}}|< \frac1{s_{t_k}}$, which approaches 0 as $k$ goes to infinity.  So $L=M$.

Because $f$ is continuous, $\lim_{i \rightarrow \infty}f(X_i) = \lim_{i \rightarrow \infty}f(Y_i) = f(L)$.

This implies that $\lim_{i \rightarrow \infty}(f(X_i) - f(Y_i)) = f(L) - f(L) = 0$.

But this is impossible, because $|f(X_i) - f(Y_i)| = |f(x_{s_{t_i}}) - f(x_{s_{t_i}})| \geq \epsilon$ for
every $i$.

So our assumption that $f$ was not uniformly continuous must be false.




\end{description}



\end{document}
\documentclass[12pt]{article}

\title{Math 314 Spring 2024 Sample Test I}

\author{Randall Holmes}

\usepackage{amssymb}

\begin{document}

\maketitle

This paper should have the same look and feel as your actual exam.

There will be 8 problems, organized in groups of two.  In each group, your score will be 70 percent based on the problem you do better on, and 30 percent on the other.
The weight of the pair of problems on which you personally do worst could be reduced:  this is one of my favorite ways to fix a bad grade distribution.

It will be a closed book, closed notes exam.  There will be an appendix supplying access to axioms and logical rules for sections that need them.

Full solutions to the practice test will be supplied some time before the exam.

{\bf I have added the reference material at the end of the sample exam just as it will appear at the end of the actual exam.  It is not intended to be read in detail during the exam;  it is really there to provide reference for names of rules and axioms.  It's probably a good idea to study it in advance so you will need to spend minimal time looking at it during the actual exam.}

\newpage

\begin{enumerate}

\section{First Pair}

\item[]This pair of problems is on truth table reasoning.

\item  Using truth tables, verify that a conditional statement (an implication) $P \rightarrow Q$  is logically equivalent to its contrapositive and not logically equivalent to its converse and inverse (and that the converse and inverse are equivalent to each other).  You should know what these words mean.

Highlight relevant columns in the truth table and say in English what facts about them support your statements of equivalence or inequivalence.

\newpage

\item  I present two logical arguments.  One is valid and one is not.  Give truth table verification that one argument is valid and the other isn't, and explain in English what facts about the truth tables make the arguments valid or invalid.

Your tables should have labelled columns for the premises and conclusion of the arguments being analyzed, and the rows should be numbered because you will want to talk about them in your explanations.

$$\begin{array}{c}

P \rightarrow Q \\

\neg Q \\ \hline

\neg P\end{array}$$

The argument above is called {\em modus tollens\/}

$$\begin{array}{c}

P \rightarrow Q \\

\neg P \\ \hline

\neg Q\end{array}$$

The argument above is called {\em denying the antecedent\/}

\newpage

\section{Second Pair}

This pair of problems is on the formal rules for propositional logic (natural deduction)

\item  Using natural deduction, prove the theorem $$((P \rightarrow Q) \wedge (Q \rightarrow R)) \rightarrow (P \rightarrow R)$$

\newpage

\item  Using natural deduction, verify the rule of {\em destructive dilemma\/}

$$\begin{array}{c}

P \rightarrow Q\\

R \rightarrow S\\

\neg Q \vee \neg S \\ \hline

\neg P \vee \neg R


\end{array}
$$

There are two different ways to prove this, one using proof by cases on the third premise, and one using alternative elimination on the conclusion.
Giving both of these proofs could carry extra credit.

\newpage


\section{Third Pair}

This pair of problems is on somewhat informal proofs about parity and divisibility, giving us a chance to think about quantifiers without being completely abstract.

\item   Prove that the product of an odd integer and an even integer is even.   Start by rephrasing the statement in a way that makes it clear
that it is a universally quantified implication.

\newpage

\item  Show that for any integers $d,m,n$, if $d|m$ and $d|n$, then $d|(m-n)$.

\newpage

\section{Fourth Pair}

This pair of problems is about formal arithmetic (which we are talking about Wednesday and Monday)

\item  Prove using the axioms of formal arithmetic (which you can read from the notes for the practice test, but they will be supplied with your exam paper)
that $1+1 = 2$, where $1$ is defined as $S(0)$ and $2$ is defined as $S(1)$ [and so as $S(S(0))$.  We will do similar things on Wednesday and Monday before the exam; you should have orientation for this after the lecture on the 21st.

\newpage

\item   Prove using the axioms of formal arithmetic that for any natural numbers $m$ and $n$, $S(m)+n = S(m+n)$.  This is a proof by induction;  you will see me write it because it is a lemma in the proof of commutativity of addition.

\newpage


\end{enumerate}

\section{Proof strategies from the manual of logical style.  These are not here for you to read in detail:  they are here so you can look up names of rules!}

\subsection{Conjunction}

In this section we give rules for handling ``and''.  These are so simple that we barely notice that they exist!

\subsection{Proving a conjunction}

To prove a statement of the form $A \wedge B$, first prove $A$, then prove
$B$.

This strategy can actually be presented as a rule of inference:

$$\begin{array}{l} A \\ B \\ \hline A \wedge B \end{array}$$

If we have hypotheses $A$ and $B$, we can draw the conclusion $A \wedge B$:  so a strategy for proving $A \wedge B$ is to first prove $A$ then prove $B$.  This gives a proof in two parts, but notice that there are no assumptions being introduced in the two parts:  they are not separate cases.

If we give this rule a name at all, we call it ``conjunction".

\subsubsection{Using a conjunction}

If we are entitled to assume $A \wedge B$, we are further entitled to assume $A$ and $B$.  This can be summarized in two rules of inference:

$$\begin{array}{l} A \wedge B \\ \hline A \end{array}$$

$$\begin{array}{l} A \wedge B \\ \hline B \end{array}$$

This has the same flavor as the rule for proving a conjunction:  a conjunction just breaks apart into its component parts.

If we give this rule a name at all, we call it ``simplification".

\subsection{Implication}

In this section we give rules for implication.  There is a single basic rule for implication in each subsection, and then some derived rules which also involve negation, based on the equivalence of an implication with its contrapositive.  These are called derived rules because they can actually be justified in terms of the basic rules.  We like the derived rules, though, because they allow us to write proofs more compactly.

\subsubsection{Proving an implication}

\begin{description}

\item[The basic strategy for proving an implication:]  To prove $A \rightarrow B$, add $A$ to your list of assumptions and prove $B$; if you can do this, $A \rightarrow B$ follows without the additional assumption.

Stylistically, we indent the part of the proof consisting of statements depending on the additional assumption $A$:  once we are done proving $B$ under the assumption and thus proving $A \rightarrow B$ without the assumption, we discard the assumption and thus no longer regard the indented group of lines as proved.

This rule is called ``deduction".

\item[The indirect strategy for proving an implication:]  To prove $A \rightarrow B$, add $\neg B$ as a new assumption and prove $\neg A$:  if you can do this, $A \rightarrow B$ follows without the additional assumption.  Notice that this amounts to proving $\neg B \rightarrow \neg A$ using the basic strategy, which is why it works.

This rule is called ``proof by contrapositive" or ``indirect proof".

\end{description}

\subsubsection{Using an implication}

\begin{description}

\item[modus ponens:]  If you are entitled to assume $A$ and you are entitled to assume $A \rightarrow B$, then 
you are also entitled to assume $B$.  This can be written as a rule of inference:

$$\begin{array}{l} A \\A \rightarrow  B \\ \hline B \end{array}$$

\item[when you just have an implication:]  If you are entitled to assume $A \rightarrow B$, you may at any time adopt $A$ as a new goal, for the sake of proving $B$, and as soon as you have proved it, you also are entitled to assume $B$.  Notice that no assumptions are introduced by this strategy.  This proof strategy is just a restatement of the rule of {\em modus ponens\/} which can be used to suggest the way to proceed when we have an implication without its hypothesis.

\item[modus tollens:]  If you are entitled to assume $\neg B$ and you are entitled to assume $A \rightarrow B$, then 
you are also entitled to assume $\neg A$.  This can be written as a rule of inference:

$$\begin{array}{l} A \rightarrow  B \\ \neg B \\ \hline \neg A \end{array}$$

Notice that if we replace $A \rightarrow B$ with the equivalent contrapositive $\neg B \rightarrow \neg A$, then this becomes an example of modus ponens.  This is why it works.

\item[when you just have an implication:]  If you are entitled to assume $A \rightarrow B$, you may at any time adopt $\neg B$ as a new goal, for the sake of proving $\neg A$, and as soon as you have proved it, you also are entitled to assume $\neg A$.  Notice that no assumptions are introduced by this strategy.  This proof strategy is just a restatement of the rule of {\em modus tollens\/} which can be used to suggest the way to proceed when we have an implication without its hypothesis.

\end{description}

\subsection{Absurdity}

The symbol $\perp$ represents a convenient fixed false statement.   The point of having this symbol is that it makes the rules for negation much cleaner.

\subsubsection{Proving the absurd}

We certainly hope we never do this except under assumptions!  If we are entitled to assume $A$ and we are entitled to assume $\neg A$, then we are entitled to assume $\perp$.  Oops!  This rule is called {\em contradiction\/}.

$$\begin{array}{r} A \\ \neg A \\ \hline \perp \end{array}$$

\subsubsection{Using the absurd}

We hope we never really get to use it, but it is very useful.  If we are entitled to assume $\perp$, we are further entitled to assume $A$ (no matter what $A$ is).  From a false statement, anything follows.  We can see that this is valid by considering the truth table for implication.

This rule is called ``absurdity elimination" or ``ex falso".

\subsection{Negation}

The rules involving just negation are stated here.  We have already seen derived rules of implication using negation, and we will see derived rules of disjunction using negation below.

\subsubsection{Proving a negation}

\begin{description}

\item[direct proof of a negation (basic):]  To prove $\neg A$, add $A$ as an assumption and prove $\perp$.  If you complete this proof of $\perp$ with the additional assumption, you are entitled to conclude $\neg A$ without the additional assumption (which of course you now want to drop like a hot potato!).  This is the direct proof of a negative statement:  proof by contradiction, which we describe next, is subtly different.

Call this rule ``negation introduction".

\item[proof by contradiction (derived):]  To prove a statement $A$ of any logical form at all, assume $\neg A$ and prove $\perp$.
If you can prove this under the additional assumption, then you can conclude $A$ under no additional assumptions.  Notice that the proof by contradiction of $A$ is a direct proof of the statement $\neg\neg A$, which we know is logically equivalent to $A$; this is why this strategy works.

Call this rule ``reductio ad absurdum".

\end{description}

\subsubsection{Using a negation:}

\begin{description}

\item[double negation (basic):]  If you are entitled to assume $\neg\neg A$, you are entitled to assume $A$.  Call this rule ``double negation elimination".

\item[contradiction (basic):]  This is the same as the rule of contradiction stated above under proving the absurd:
if you are entitled to assume $A$ and you are entitled to assume $\neg A$, you are also entitled to assume $\perp$.  You also feel deeply queasy.

$$\begin{array}{r} A \\ \neg A \\ \hline \perp \end{array}$$

\item[if you have just a negation:] If you are entitled to assume $\neg A$, consider adopting $A$ as a new goal:  the point of this is that from $\neg A$ and $A$ you would then be able to deduce $\perp$ from which you could further deduce whatever goal $C$ you are currently working on.  This is especially appealing as soon as the current goal to be proved becomes $\perp$, as the rule of contradiction is the only way there is to prove $\perp$.

\end{description}

\subsection{Disjunction}

In this section, we give basic rules for disjunction which do not involve negation, and derived rules which do.  The derived rules can be said to be the default strategies for proving a disjunction, but they {\em can\/} be justified using the seemingly very weak basic rules (which are also very important rules, but often used in a ``forward" way as rules of inference).   The basic strategy for using an implication (proof by cases) is of course very often used and very important.  The derived rules in this section are justified by the logical equivalence of $P \vee Q$ with both $\neg P \rightarrow Q$ and $\neg Q \rightarrow P$:  if they look to you like rules of implication, that is because somewhere underneath they are.

\subsubsection{Proving a disjunction}

\begin{description}

\item[the basic rule for proving a disjunction (two forms):]  To prove $A \vee B$, prove $A$.   Alternatively, to prove $A \vee B$, prove $B$.
You do {\em not\/} need to prove both (you should not expect to be able to!)

This can also be presented as a rule of inference, called {\em addition\/}, which comes in two different versions.

$$\begin{array}{r} A \\ \hline A \vee B \end{array}$$

$$\begin{array}{r} B \\ \hline  A \vee B \\ \end{array}$$

\item[the default rule for proving a disjunction (derived, two forms):]   To prove $A \vee B$, assume $\neg B$ and attempt to prove $A$.  If $A$ follows with the additional assumption, $A \vee B$ follows without it.  

Alternatively (do not do both!):  To prove $A \vee B$, assume $\neg A$ and attempt to prove $B$.  If $B$ follows with the additional assumption, $A \vee B$ follows without it.

Notice that the proofs obtained by these two methods are proofs of $\neg B \rightarrow A$ and $\neg A \rightarrow B$ respectively, and both of these are logically equivalent to $A \vee B$.  This is why the rule works.  Showing that this rule can be derived from the basic rules for disjunction is moderately hard.

Call both of these rules ``disjunction introduction", or ``alternative elimination".


\end{description}


\subsubsection{Using a disjunction}

\begin{description}

\item[proof by cases (basic):]  If you are entitled to assume $A \vee B$ and you are trying to prove $C$, first assume $A$ and prove $C$ (case 1);
then assume $B$ and attempt to prove $C$ (case 2).  

Notice that the two parts are proofs of $A \rightarrow C$ and $B \rightarrow C$,
and notice that $(A \rightarrow C) \wedge (B \rightarrow C)$ is logically equivalent to $(A \vee B) \rightarrow C$ (this can be verified using a truth table).

This strategy is very important in practice.


\item[disjunctive syllogism (derived, various forms):]  If you are entitled to assume $A \vee B$ and you are also entitled to assume $\neg B$, you are further entitled to assume $A$.  Notice that replacing $A \vee B$ with the equivalent $\neg B \rightarrow A$ turns this into an example of modus ponens.


If you are entitled to assume $A \vee B$ and you are also entitled to assume $\neg A$, you are further entitled to assume $B$.  Notice that replacing $A \vee B$ with the equivalent $\neg A \rightarrow B$ turns this into an example of modus ponens.

Combining this with double negation gives further forms:  from $B$ and $A \vee \neg B$ deduce $A$, for example.

Disjunctive syllogism in rule format:

$$\begin{array}{r}  A \vee B \\ \neg B \\ \hline A \end{array}$$

$$\begin{array}{r}  A \vee B \\ \neg A \\ \hline B \end{array}$$

Some other closely related forms which we also call ``disjunctive syllogism":

$$\begin{array}{r}  A \vee \neg B \\ B \\ \hline A \end{array}$$

$$\begin{array}{r}  \neg A \vee B \\ A \\ \hline B \end{array}$$

\end{description}

\subsection{Biconditional}

Some of the rules for the biconditional are derived from the definition of $A \leftrightarrow B$ as $(A \rightarrow B) \wedge (B \rightarrow A)$.  There is a further very powerful rule allowing us to use biconditionals to justify replacements of one expression by another.

\subsubsection{Proving biconditionals}

\begin{description}

\item[the basic strategy for proving a biconditional:]  To prove $A \leftrightarrow B$, first assume $A$ and prove $B$; then (finished with the first assumption) assume $B$ and prove $A$.  Notice that the first part is a proof of $A \rightarrow B$ and the second part is a proof of $B \rightarrow A$.

Call this rule ``biconditional introduction".

\item[derived forms:]  Replace one or both of the component proofs of implications with the contrapositive forms.  For example one could first
assume $A$ and prove $B$, then assume $\neg A$ and prove $\neg B$ (changing part 2 to the contrapositive form).

\end{description}

\subsubsection{Using biconditionals}  The rules are all variations of modus ponens and modus tollens.   Call them biconditional modus ponens (bimp)
or biconditional modus tollens (bimt) as appropriate.

If you are entitled to assume $A$ and $A \leftrightarrow B$, you are entitled to assume $B$.

If you are entitled to assume $B$ and $A \leftrightarrow B$, you are entitled to assume $A$.

If you are entitled to assume $\neg A$ and $A \leftrightarrow B$, you are entitled to assume $\neg B$.

If you are entitled to assume $\neg B$ and $A \leftrightarrow B$, you are entitled to assume $\neg A$.

These all follow quite directly using modus ponens and modus tollens and one of these rules:

If you are entitled to assume $A \leftrightarrow B$, you are entitled to assume $A \rightarrow B$.

If you are entitled to assume $A \leftrightarrow B$, you are entitled to assume $B \rightarrow A$.

The validity of these rules is evident from the definition of a biconditional as a conjunction.


\section{Basic Concepts and Axioms of Formal Arithmetic}

All of our objects are natural numbers.  We denote the set of natural
numbers by ${\mathbb N}$; we will actually not need to refer to it in
these sections as the universe is inhabited only by natural numbers.
We have the following basic concepts:  0 (a particular natural number)
and the operations $S(x)$ (successor of $x$), addition and multiplication.

\begin{enumerate}

\item 0 is a natural number (in symbols, $0 \in {\mathbb N}$).  [this axiom is never really used because of our domain assumption that everything is a natural number]

\item If $x$ and $y$ are natural numbers, so are $S(x)$, $x+y$, and $x
\cdot y$.  $(\forall xy \in {\mathbb N}.S(x) \in {\mathbb N} \wedge
x+y \in {\mathbb N} \wedge x \cdot y \in {\mathbb N})$.  [this axiom is never really used because of our domain assumption that everything is a natural number]

\item 0 is not a successor.  $(\forall x.S(x) \neq 0)$.  Here we
understand that $x\neq y$ abbreviates $\neg x=y$.  Here and in the
following axioms we write our quantifiers unrestricted: we could write
$(\forall x \in {\mathbb N}.S(x) \neq 0)$ instead, but in this context
we are only talking about natural numbers, so we can leave the
restriction on our quantifiers implicit.

\item Numbers with the same successor are the same.  $(\forall xy.S(x)
= S(y) \rightarrow x=y)$.

\item Let P(x) be any sentence about a natural number variable $x$.
We assert $P(0) \wedge (\forall y.P(y) \rightarrow P(S(y)))
\rightarrow (\forall x.P(x))$.  This is a symbolic presentation of the
familiar principle of mathematical induction.  From an extremely
technical standpoint, this is an infinite collection of axioms, one
for each sentence $P(x)$.  If we are also willing to talk about sets
of natural numbers, we can state it as a single axiom: $(\forall A \in
{\cal P}({\mathbb N}).0 \in A \wedge (\forall y \in {\mathbb N}.y \in
A \rightarrow S(y) \in A) \rightarrow A = {\mathbb N})$.  We will not
use the set formulation now but we might use it later.  ${\cal
P}({\mathbb N})$ is a notation for the collection of all sets of
natural numbers.

\item $(\forall x.x+0=x)$

\item $(\forall xy.x+S(y)=S(x+y))$

\item $(\forall x.x\cdot 0 = 0)$

\item $(\forall xy.x \cdot S(y) = x\cdot y +x)$  Here we assume the usual order of operations.
% Becerra editing point
\end{enumerate}

\newpage

\section{Equality style manual}

Here I am going to list examples of expected and allowed justifications of lines using properties of equality.  I show snippets of proof under each rule.  Again, if you have to read this in detail, you are not making correct use of it.  Its a reference for names of rules.

\begin{description}

\item[Reflexivity of equality]

\begin{description}

\item

\item[117:]  2+2 = 2+2   ref =

\end{description}

\item[Substitution]

\begin{description}

\item

\item[12:]  $A = B$

\item[more lines not shown] $\ldots$

\item[53:]  $P(A)$  (notice this is any statement about $A$)

\item[more lines not shown]  $\ldots$

\item[117:]  $P(B)$  substitution using line 12 into line 53

\end{description}

\item[Symmetry]

\begin{description}

\item

\item[12]  $A=B$

\item[more lines not shown]  $\ldots$

\item[32]  $B=A$  symm = line 12


\end{description}

\item[Transitivity]

order of the premises doesnt matter, if 22 and 72 were interchanged this would still work

\begin{description}

\item

\item[22]  $A=B$

\item[more lines not shown] $\ldots$

\item[72]  $B=C$

\item[more lines not shown] $\ldots$

\item[117]  $A=C$  trans = 22,72

\end{description}

\item[Symmetry and Transitivity]

order of the premises doesnt matter.  These are both ``things equal to the same thing are equal to each other".

\begin{description}

\item


\item[3]  $A=B$

\item[more lines not shown] $\ldots$

\item[21]  $A=C$

\item[more lines not shown] $\ldots$

\item[104]  $B=C$  symm trans = 3,21

\end{description}

or 

\newpage

\begin{description}


\item[3]  $B=A$

\item[more lines not shown] $\ldots$

\item[21]  $C=A$

\item[more lines not shown] $\ldots$

\item[104]  $B=C$  symm trans = 3,21

\end{description}

\item[Chained transitivity (and possibly symmetry)]

Chains of equations of any length may be handled in a single line.

\begin{description}

\item[57]  $A=B$

\item[more lines not shown] $\ldots$

\item[61]  $D=E$

\item[more lines not shown] $\ldots$

\item[72]  $C=B$

\item[more lines not shown] $\ldots$

\item[82]  $C=D$

\item[more lines not shown] $\ldots$

\item[99]  $A=D$, chain of equations, lines 57,72,82,61  (notice that I put the premises in the correct order for the chain in the justification)

\end{description}

\item[Doing the same thing to both sides]

\begin{description}

\item

\item[18:]  $A=B$

\item[more lines not shown] $\ldots$

\item[53] $F[A]=F[B]$   both sides, line 18

\end{description}

(where $F[A]$ is any complex expression in which replacing some $A$'s with $B$'s will give $F[B]$)

\newpage

This saves a line from the following approach to proving the same thing

\begin{description}

\item

\item[18:]  $A=B$

\item[more lines not shown] $\ldots$

\item[52]  $F[A] = F[A]$  ref =

\item[53] $F[A]=F[B]$   substitution into line 52 using line 18

\end{description}

\item[Something I think is too short]

\begin{description}

\item

\item[12]  $S(S(a)) = S(b)$  who knows why?

\item[72]  $S(S(a)) = S(b+0)$  axiom 6, $x:=b$, subs

\end{description}

I think that is too short.  The instance of axiom 6 that you use is never written down at all.  I want you to write

\begin{description}

\item

\item[12]  $S(S(a)) = S(b)$  who knows why?

\item[71]  $b=b+0$  axiom 6, $x:=b$

\item[72] $S(S(a))=S(b)$  substitution using line 71 into line 12

\end{description}

I may use the first style, with the extra remark subs to signal the cheat, in board work, but I will use the second one in
the notes and I expect you to use the second one in homework.

\end{description}

\newpage

\section{Induction presented as a proof strategy}

In this system of formal arithmetic, most of the power is included in
the axiom of mathematical induction.  This principle is already
familiar to you, and my presentation of it as a proof strategy similar
to the proof strategies we presented above in propositional and
quantifier logic should not really be surprising.

\begin{description}

\item[Goal:]  $(\forall x \in {\mathbb N}.P(x))$

\begin{description}

\item[Basis:]  Goal:  $P(0)$

\item[Induction Step:]  (Goal:  $(\forall y\in \mathbb N.P(y) \rightarrow P(S(y)))$) writing this goal is optional.

\begin{description}

\item[Let]  $k$ be an arbitary natural number.

\item[Assume (inductive hypothesis):]  $P(k)$

\item[Induction Goal:]  $P(S(k))$ [or $P(k+1)$]

\end{description}

\end{description}

\end{description}

This is exactly the strategy for proving $P(0) \wedge (\forall k.P(k)
\rightarrow P(S(k)))$, and axiom 5 tells us that this implies $(\forall
x.P(x))$.  This statement is NOT part of the proof outline: you do not
need to repeat it after every induction proof.  It's just a remark
about why the proof outline works.

We state the quantifiers explicitly in the proof outline because we
will also use this principle in the more general setting of real
analysis where not all objects are natural numbers [you do not need to restrict your quantifiers
to $\mathbb N$ in the proofs on this test]
\end{document}
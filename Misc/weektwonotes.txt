Greetings students.

In this second week, I am coming to grips with the rather alarming format of our course:  
I need to communicate content to you over the course of a week which I would normally
cover in three periods with substantial lecture in each period.

This week I am going to try to produce a summary lecture and record it for your benefit, 
covering the basic ideas you need to imbibe this week.

I am also going to post for you these notes in nasty ASCII format, which are my notes for preparing the video.

The video is, as of Sunday night, recorded but not yet exported to where you all can see it.

There are three headings: 

1.  the dot product (and its applications)

2.  the cross product (and its applications)

3.  equations of lines and planes.  Notice that Dr. Kaiser covered equations of lines in his 
lecture 2 on vectors in three dimensional space.  Equations of planes are new, of course.


Heading 1

The dot product, like others of our concepts, has both an algebraic and a geometric definition.

The geometric definition says that the dot product of two vectors is the product of the 
lengths of the two vectors and the cosine of the angle between them:
u . v = |u| * |v| * cos(theta)

The algebraic definition says that

<a,b> . <c,d> = ac + bd (two dimensions)

and

<a,b,c> . <d,e,f> = ad + be + cf (three dimensions)

Both definitions have in common that one multiplies two vectors 
(in space of the same dimension) and outputs a scalar (a real number)

The fact that the very simple algebraic definition coincides with the more complicated 
and indeed trigonometric geometric definition is a source of power.  It is the basis
for the numerous applications of this idea.

One immediate application is that we can compute the cosine of the angle between 
two vectors as (u . v)/(|u| * |v|).  From this, by mashing our calculator, we can compute the angle!

theta = arccos((u . v)/(|u| * |v|))  [arccos is also written cos^{-1}]

[do an example]

A special case which is extremely important is that if u . v is 0 we can determine 
that the angle between them is pi/2 = ninety degrees.  
They are perpendicular or "orthogonal" (a perhaps less familiar word for the same thing).

Another special equation we should bear in mind is u . u = |u|^2

This follows immediately from the geometric definition, 
since the angle theta in this case is zero and the cosine of zero is one.

It also follows immediately from the componentwise definition:  for example, in three dimensions

<a,b,c> . <a,b,c> = a^2 + b^2 + c^2, 

and we already know that this is the square of the length of <a,b,c>.

The fact that the algebraic and geometric definitions are equivalent 
is so powerful that we really ought to support it with a demonstration.
A picture [supplied in the video lecture] and the Law of Cosines tell us that

|u-v|^2  = |u|^2 + |v|^2 - 2|u||v| cos(theta)

where theta is the angle between u and v.

Now |u-v|^2 = (u-v) . (u-v) = (u.u) - 2(u.v) + (v.v)

(that the dot product distributes over vector addition and subtraction as required
can be verified by computation from the algebraic definition:  we are not cheating)

so |u-v|^2 = |u|^2 + |v|^2 - 2(u.v)

so |u|^2 + |v|^2 - 2|u||v| cos(theta) = |u|^2 + |v|^2 - 2(u.v)

from which the equation 

u.v = 2|u||v|cos(theta) follows by straightforward algebra manipulations.

A consequence of our formula for angles is that for a vector u = <a,b,c> we have
the cosine of the angle between u and the x-axis equal to (u.i)/|u||i| which is just a/|u|
(i being the unit basis vector <1,0,0>).  Similarly the cosine of the angle between u
and the y-axis will be b/|u| and the cosine of the angle between u and the z-axis will
be c/|u|:  these are called the direction cosines, and can be recognized also as the 
components of the unit vector in the direction of u.

From the direction cosines you can of course compute the angles between a vector
and the coordinate axes by taking the arc cosine.

A really important idea which needs to be supported with a picture, 
which I cannot put in this text
file [it will be in the video] is the notion of 
vector projection of a vector b onto a vector a.
The basic idea is that b is the sum in a unique way 
of a vector parallel to a and a vector perpendicular to
a:  the parallel vector is the component of b in the direction of a.

Note further that for example we expect the vector projection 
of <a,b,c> onto i, the unit vector in the direction
of the x-axis, to be the vector <a,0,0>.

The vector projection will be written proj_a(b).  
Trigonometry tells us that if theta is the angle between a and b,
the length of proj_a(b) will be the absolute value of |b|cos(theta), 
and if the cosine of theta is negative (so the 
angle is obtuse) proj_a(b) will point in the opposite direction from a.

In other words, we can express proj_a(b) as |b|cos(theta)(a/|a|), 
multiplying |b|cos(theta) by the unit vector in the direction of a.

Now (using the unreasonable power of our algebraic representation of
a.b) we can express this is |b|(a.b)/(|a||b|))(a/|a|) which simplifies to
[(a.b)/|a|][a/|a|] or even further to [(a.b}/|a|^2]a or even
[(a.b)/(a.a)]a  You can see from this last calculation that we should
not express a computation with vectors with nice component form to
even lead to square roots.

The signed length of the vector projection, written comp_b(a) [it is not
just the length:  it is negative if 
the projection points in the opposite direction of a]
is written (a.b)/|a|.  "comp"  abbreviates "component".

We have comp_b(a)[a/|a|] = proj_b(a):  
the component is the scalar multiplier to be
applied to the unit vector in the direction of a 
to get the projection vector.

Notice that comp_i<a,b,c> = a, comp_j<a,b,c>, comp_k<a,b,c> = c
as you should expect.

If we set up different coordinate systems, the projection machinery could
be used to compute coordinates with respect to the new axes (among other uses).

On pages 811 and 812 find the discussion of the use of components and projections
in computing work.  This really turns out to be a quite direct dot product computation.

Heading 2  The Cross Product

This is really a piece of black magic.

The cross product a x b of two vectors a,b in three dimensional space is a vector.

Its geometrical meaning is that it is perpendicular to a, perpendicular to b,
its length is |a||b|sin(theta)  and if the lengths of a, b, axb are nonzero they form
a right handed system (in the same sense that the x,y,z axes form a right handed system).

Its computational meaning is where the black magic comes in.

<a_1,a_2,a_3><b_1,b_2,b_3> = 

<a_2b_3 -a_3b_2, a_3b_1 - a_1b_3, a_1b_2 -a_2b_1>



|i   j   k   |i   j

|a_1 a_2 a_3 |a_1 a_2

|b_1 b_2 b_3 |b_1 b_2

which looks formally like the calculation of an entirely illegal
3x3 determinant.  I'll lecture the method of computation of a 3x3 determinant
which I am using on the video.  I do warn you that this method of computing
determinants does NOT generalize to higher dimensions.

You can compute (by computing a.(a x b), b.(a x b)) that
the perpendicularity conditions hold:  both of these dot
products will be zero.  I am not going to do this
symbolically.  I do strongly suggest checking perpendicularity when
you compute a cross product for specific numbers:  the dot products
are easy to compute and give a cross check

[do this with specific numbers in the video]

The algebraic properties of the cross product include one seriously
unfamiliar feature:  b x a = -(a x b).  Understanding why this follows from the 
geometric definition should not be hard:  if we reverse the order of the x
and y axes, for example, and still want a right handed coordinate system,
then the z-axis has to point in the opposite direction.

Applications:

If we want a vector perpendicular to two given vectors, the cross product works.

|a x b| is the area of the parallelogram formed from the vectors a,b in the obvious way
(that this is |a||b|sin(theta) is immediate from trigonometry).

That |a x b| really is the absolute value of |a||b|sin(theta) 
could be verified by verifying the identity

(a.b)^2 + |a x b|^2 = |a|^2|b|^2, which could be done by calculations with component
form, but we won't!

a.(b x c), the triple product of three vectors, is equal to

|a_1 a_2 a_3|
|b_1 b_2 b_3|
|c_1 c_2 c_3|

There is a 3x3 determinant again!  The absolute value |a.(b x c)|
is the volume of the paralleliped (slanted box) produced by the
vectors in the obvious way.  Notice that a.(b x c) = 0
tells you that the vectors lie in the same plane.  The sign
of a.(bxc) gives you handedness information.

Being able to compute cross products is really useful.  The best way to master it
is the determinant shortcut.

Heading 3  Equations of Lines and Planes

Dr Kaiser lectured this in his video 2, so you have already seen some discussion.

A line is given if we have certain data.

If we are given a point P on the line and a nonvector v parallel to the line, then
let x be the standard vector OP and we can compute the standard vector of any point Q on
the line as being of the form x + tv where t is a scalar.

We can verify this, because the vector PQ is parallel to v by hypothesis, 
so is a scalar multiple tv, and OP + PQ = OQ, so OQ is x + tv 
for some scalar t as claimed.  (O here is the origin).

Of course, the classic data for a line are two points.  If we have two distinct points
P and Q with given coordinates, we can use the vector PQ or the vector QP along with
either P or Q to represent the vector as above.

[give an example of computing vector parametric equations for
the line between two given points]

If we are given vector parametric equations <x_0,y_0,z_0>+t<a,b,c> for a line
we can get scalar parametric equations from them:

x = x_0 + ta

y = y_0 + tb

z = z_0 + tc

and from these we can derive the symmetric equations for a line

(x-x_0)/a = (y-y_0)/b = (z-z_0)/c

None of these forms are unique, because we can choose any point on a line
as the basic point and any scalar multiple of a given nonzero vector as the
basic direction.

To recognize that two lines are the same, it is fairly easy to determine
whether their vectors are parallel (seeing that one is a scalar multiple of the other
is not difficult);  then check whether the base point on the one line satisfies
the symmetric equations for the other.

To tell whether two distinct lines intersect 
and where they intersect will reduce to solving
simultaneous equations.

Example 3 page 826 demonstrates that two lines in 3-space dont intersect at all:
but the same procedure should give a hint as to how to find the intersection if it
actually exists:  if a value of s and a value of t were found that DID work, then plugging
them into the original equations for the lines would give the point of intersection.

Do section 12.5 problem 21.  Also talk about different equations for the lines presented.

Equations of Planes

The data for a plane which might occur to you first from geometry are three points in the plane.
But this is not the natural set for our purposes.

Another natural set of data might be a point in the plane 
and two non-parallel vectors parallel to it.  Then
a general point  would be of the form x + su + tv, where x is the
standard vector associated with the point, u and v are the two vectors
and s,t are two scalar parameters.

But we don't do it that way, either.

A plane can be characterized in 3-space as the set of points Q such that for a given point P,
PQ is perpendicular to a given vector n.  n is for "normal", we call this a normal vector to the
plane.  All normal vectors to a plane are parallel to each other, so it is easy to recognize
when two planes have the same normal vector (up to a constant factor) and so are parallel.

The equation we get for a plane is then n.(X-X_0) = 0

The idea is that x_0 is the vector OP,  x is the vector OQ:  then x-x_0 is the vector PQ
and we have the same definition as above.  But this is computational, because we have a firm
computational grasp of the dot product and subtraction of vectors!

If n = <a,b,c>, X = <x,y,z>, X_0=<x_0,y_0,z_0>  this becomes

a(x-x_0) + b(y-y_0) + c(z-z_0) = 0

which can easily be put in the form

ax+by+cz+d = 0

Notice that from an equation of the plane in either of the last two forms we can
easily read a normal vector to it.

Cross products are really useful here.

If we are given points P, Q, R in a plane, not all in the same line.
then PQ and PR are two vectors in the plane, and PQ x PR is a normal vector
to the plane, which we can then use with any of the three points to give
standard form equations for the plane.

Do Example 5 p. 828

The angle between two planes is the angle between their normal vectors.

The cross product of the normal vectors of two planes gives a vector parallel to their
line of intersection.  If you then find a point on both planes, you have equations
for the line of intersection.

Do Example 7, p. 828-9.

The distance from a point Q to a plane containing a point P is the scalar projection
(component) of the vector PQ in the direction of the normal vector of the plane.  This is 
used in example 8 to actually derive a general formula for this distance.

The distance between parallel planes is the distance from any point on one of the planes
to the other plane:  choose a point P on one of the planes, a point Q on one of the other planes,
and project the vector PQ onto the common normal vector of the two planes (any normal vector
for one of them is also a normal vector for the other, because they are parallel;  it doesnt
matter which one you use).

The distance between skew lines is a last rather nasty example.  The key idea is that
if L_1 is parallel to vector u and L_2 is parallel to vector v, one should see that
the shortest vector from a point on L_1 to a point on L_2, whose length is the distance you
want, is perpendicular to both lines and so parallel to u x v.  So the distance from L_1
to L_2 can be found by taking any point P on L_1, any point Q on L_2, and then
computing the magnitude of the projection of the vector PQ onto u x v.  They didn't explain
it exactly this way in example 10, but you can check that the same answer would be obtained.




















